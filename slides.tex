\documentclass[onlymath]{beamer}
%\usepackage[affil-it]{authblk}


\usetheme{default}
\usecolortheme{beaver}

\setbeamercolor{block title}{use=structure,fg=white,bg=structure.fg!75!black}
\setbeamercolor{block body}{parent=normal text,use=block title,bg=block title.bg!10!bg}

\addtobeamertemplate{navigation symbols}{}{%
	\usebeamerfont{footline}%
	\usebeamercolor[fg]{footline}%
	\hspace{1em}%
	\insertframenumber/\inserttotalframenumber
}

%quasi-historischer Header:
\usepackage{verbatim}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{ulem}
%\usepackage{scrextend}
%
%\usepackage{microtype} % get rid of bad boxes (overful hbox) in bibliography {https://www.mrunix.de/forums/showthread.php?76019-Biblatex-Overfull-Boxes-im-Literaturverzeichnis-beheben-kein-minimal-bsp}
%
%\usepackage{csquotes} % {"When using babel or polyglossia with biblatex, loading csquotes is recommended to ensure that quoted texts are typeset according to the rules of your main language."} {https://tex.stackexchange.com/questions/229638/package-biblatex-warning-babel-polyglossia-detected-but-csquotes-missing/229653}
%
%\usepackage[backend=biber]{biblatex}
%\addbibresource{bibliography.bib}
%
%%\usepackage{algorithm}
%%\usepackage{algorithmicx}[noend]
\usepackage{bbold}
%\usepackage[noend]{algpseudocode}
\usepackage{colonequals}
%
%\usepackage[official]{eurosym} % € - Symbol
%
\newcommand{\mc}{Markow-Kette}

\title{Analyse eines Forschungsthemas\\
Stochastic Shortest Paths
}
\author{Maximilian Starke}
\institute[VFU] % (optional)
{
	\inst{}%
	Fakultät für Informatik\\
	Technische Universität Dresden
}
\date{\today}


%\logo{\includegraphics[height=1.5cm]{lion-logo.png}}


%
\usepackage{mathtools}
%\usepackage{ragged2e}
%
%\usepackage{framed}
%\usepackage{amsmath, amssymb}
%\usepackage{enumerate}
%\usepackage{tabularx}
%
\DeclareMathOperator*{\argmin}{\arg\min}
%
\usepackage{pgfplots}
\pgfplotsset{width=10cm,compat=1.10}
\usepgfplotslibrary{fillbetween}
%\newcolumntype{P}[1]{>{\centering\arraybackslash}p{#1}}
%
%\usepackage{listings}
%
%\newcolumntype{M}[1]{>{\centering\arraybackslash}m{#1}}
%\newcolumntype{L}[1]{>{\flushleft\arraybackslash}m{#1}}
%
%
\usepackage{tikz}
%\usepackage{verbatim}
%
\usetikzlibrary{%
	arrows,
	shapes,
	shapes.misc,% wg. rounded rectangle
	shapes.arrows,%
	chains,%
	matrix,%
	positioning,% wg. " of "
	backgrounds,
	fit,
	petri,
	scopes,%
	decorations.pathmorphing,% /pgf/decoration/random steps | erste Graphik
	shadows,%
	calc,
	angles,
	positioning,
	quotes
}
%#1
\tikzstyle{vertex}=[circle, minimum size=20pt, line width = 1pt, draw = black]
\tikzstyle{target} = [vertex, double, double distance = 1pt]
\tikzstyle{edge} = [draw,shorten > = 1pt, shorten < = 1pt, line width=1pt,->]
\tikzstyle{medge} = [draw, line width = 8pt, yellow!50]
\tikzstyle{weight} = [font=\small]
\tikzstyle{selected edge} = [draw,line width=5pt,-,red!50]
\tikzstyle{ignored edge} = [draw,line width=5pt,-,black!20]

\usepackage{relsize}
%
%\usepackage{xcolor}
%% maybe install minted some day and make syntax highlighting###
%
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath, amssymb, amsxtra, amsthm}
\usepackage{mathrsfs}
%\usepackage{enumerate}
%\usepackage{multicol} % multiple collums in enumerate
%
%\usepackage[thmmarks,amsmath,hyperref,noconfig]{ntheorem} 
%% erlaubt es, Sätze, Definitionen etc. einfach durchzunummerieren.
\newtheorem{satz}{Satz}[section] % Nummerierung nach Abschnitten
\newtheorem{proposition}[satz]{Proposition}
\newtheorem{korollar}[satz]{Korollar}
%\newtheorem{vermutung}[satz]{Vermutung}
\newtheorem*{partproof}{Beweis.}
%
%\theorembodyfont{\upshape}
%\newtheorem{beispiel}[satz]{Beispiel}
%\newtheorem{bemerkung}[satz]{Bemerkung}
%\newtheorem{algorithmus}[satz]{Algorithmus}
%%%%%%\newtheorem{beweis}[beispiel]{Beweis}

%
%\theoremstyle{nonumberplain}
%\theoremheaderfont{\itshape}
%\theorembodyfont{\normalfont}
%\theoremseparator{.}
%\theoremsymbol{\ensuremath{_\Box}}
%\newtheorem{beweis}{Beweis}
%\newtheorem{beweiss}{Beweisskizze}
%
%\qedsymbol{\ensuremath{_\Box}}
%
%\usepackage{chngcntr}
%\counterwithin{figure}{section}
%
\tikzstyle{block} = [rectangle, draw, fill=blue!40, 
text width=7em, text centered, rounded corners, minimum height=5em, node distance= 4.5cm, line width = 2pt]
%
%
\tikzstyle{cblock} = [rectangle, draw, fill=blue!40, 
text width=7em, text centered, rounded corners, minimum height=5em, node distance= 3.0cm, line width = 2pt]
%
%
\tikzstyle{line} = [draw, -latex', line width = 1pt]
%
%
\tikzstyle{cloud} = [ fill = white, rectangle, draw, rounded corners, node distance=2cm,
minimum height=2.5em]
%
\pgfdeclarelayer{bg}
\pgfsetlayers{bg,main}	
%
\pgfdeclarelayer{foreground}
\pgfdeclarelayer{background}
%% tell TikZ how to stack them (back to front)
\pgfsetlayers{bg,background,main,foreground}
%
%\newenvironment{meta}
%{\begin{center} \Large \color{red} META: \hspace{2ex} \large \color{blue}}
%	{\end{center}}
%

\AtBeginSection{\frame{\sectionpage}}
\AtBeginSubsection{\frame{\subsectionpage}}
\begin{document}	

\frame{\titlepage}

\begin{frame}
	\frametitle{Inhalt}
	\tableofcontents
\end{frame}


\section{Introduction}


	

\begin{frame}
	\begin{itemize}
		\item The \textit{simplest} shortest path problem
		\begin{center}%#2
			\begin{tikzpicture}[auto,swap,scale=3]
			
			% First we draw the vertices
			\foreach \pos/\name in {{(0,0)/{0}}, {(1,0)/1}, {(0.5,0.5)/{2}}, {(0,1)/3}, {(2,0)/4}, {(1.5,0.5)/{5}}, {(1,1)/6}}
			\node[vertex] (\name) at \pos {$\name$};
			
			% First we draw the vertices
			\foreach \pos/\name in {{(2,1)/7}}
			\node[target] (\name) at \pos {$\name$};
			
			% Connect vertices with edges and draw weights
%			\foreach \source/ \dest /\weight in {
%				1/2/{\frac{1}{2}}
%				2/6/{1},
%				5/6/{1},
%				6/5/{1}
%			}
%			\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);



			
			% Connect vertices with edges and draw weights
%			\foreach \source/ \dest /\weight in {
%				1/3/{\frac{1}{2}}
%				3/4/{\frac{1}{2}},
%				4/5/{\frac{1}{5}}
%			}
%			\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
			
			% Connect vertices with edges and draw weights
			\foreach \source/ \dest /\weight in {
				0/1/{},
				0/2/{},
				0/3/{},
				1/2/{},
				2/3/{},
				2/6/{},	
				3/6/{},
				4/7/{},
				5/1/{},
				5/4/{},
				5/7/{},
				6/5/{},
				6/7/{}	
			}
			\path[edge] (\source) to node[weight]{$\weight$} (\dest);

			\only<3>{
				\foreach \source/ \dest /\weight in {
					0/2/{},
					2/6/{},	
					6/7/{}	
				}
				\path[edge, draw=red] (\source) to node[weight]{$\weight$} (\dest);
			}
			
%			\foreach \source/ \dest /\weight in {
%				4/4/{\frac{4}{5}}
%			}
%			\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
			
			% Draw initial state
			\path[edge] (-0.5,0) to (0);
			
			\end{tikzpicture}
		\end{center}
		\pause
		\item Task
		\begin{itemize}
			\item Find the shortest path (\textit{number of hops})!
		\end{itemize}
	\end{itemize}
\end{frame}




\begin{frame}
\begin{itemize}
	\item The \textit{classical, non-stochastic, deterministic} shortest path problem
	\begin{center}%#2
		\begin{tikzpicture}[auto,swap,scale=3]
		
		% First we draw the vertices
		\foreach \pos/\name in {{(0,0)/{0}}, {(1,0)/1}, {(0.5,0.5)/{2}}, {(0,1)/3}, {(2,0)/4}, {(1.5,0.5)/{5}}, {(1,1)/6}}
		\node[vertex] (\name) at \pos {$\name$};
		
		% First we draw the vertices
		\foreach \pos/\name in {{(2,1)/7}}
		\node[target] (\name) at \pos {$\name$};
		
		% Connect vertices with edges and draw weights
		%			\foreach \source/ \dest /\weight in {
		%				1/2/{\frac{1}{2}}
		%				2/6/{1},
		%				5/6/{1},
		%				6/5/{1}
		%			}
		%			\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
		
		
		
		
		% Connect vertices with edges and draw weights
		%			\foreach \source/ \dest /\weight in {
		%				1/3/{\frac{1}{2}}
		%				3/4/{\frac{1}{2}},
		%				4/5/{\frac{1}{5}}
		%			}
		%			\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			0/1/{1},
			0/2/{3},
			0/3/{8},
			1/2/{1},
			2/3/{2},
			2/6/{7},	
			3/6/{4},
			4/7/{7},
			5/1/{2},
			5/4/{3},
			5/7/{5},
			6/5/{2},
			6/7/{9}	
		}
		\path[edge] (\source) to node[weight]{$\weight$} (\dest);
		
		\only<3>{
			\foreach \source/ \dest /\weight in {
				0/1/{1},
				1/2/{1},
				2/3/{2},
				3/6/{4},
				5/7/{5},
				6/5/{2}
			}
			\path[edge, draw=red] (\source) to node[weight]{$\weight$} (\dest);
		}
		
		
		\only<5>{
			\foreach \source/ \dest /\weight in {
				0/1/{1},
				1/2/{1},
				2/3/{2},
				3/6/{4},
				4/7/{7},
				5/7/{5},
				6/5/{2}
			}
			\path[edge, draw=red] (\source) to node[weight]{$\weight$} (\dest);
		}
		
		%			\foreach \source/ \dest /\weight in {
		%				4/4/{\frac{4}{5}}
		%			}
		%			\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
		
		% Draw initial state
		\path[edge] (-0.5,0) to (0);
		
		\end{tikzpicture}
	\end{center}
	\pause
	\item Task
	\begin{itemize}
		\item Find the path with the minimal weight sum!
		\onslide<4->{\item Give a strategy to always reach the goal while collecting minimal weight!}
	\end{itemize}
\end{itemize}
\end{frame}


\begin{frame}
\begin{itemize}
	\item The \textit{stochastic} shortest path problem
	\begin{center}%#2
		\begin{tikzpicture}[auto,swap,scale=3]
		
		% First we draw the vertices
		\foreach \pos/\name in {{(0,0)/{0}}, {(1,0)/1}, {(0.5,0.5)/{2}}, {(0,1)/3}, {(2,0)/4}, {(1.5,0.5)/{5}}, {(1,1)/6}}
		\node[vertex] (\name) at \pos {$\name$};
		
		% First we draw the vertices
		\foreach \pos/\name in {{(2,1)/7}}
		\node[target] (\name) at \pos {$\name$};
		
		% Connect vertices with edges and draw weights
		%			\foreach \source/ \dest /\weight in {
		%				1/2/{\frac{1}{2}}
		%				2/6/{1},
		%				5/6/{1},
		%				6/5/{1}
		%			}
		%			\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
		
		
		
		
		% Connect vertices with edges and draw weights
		%			\foreach \source/ \dest /\weight in {
		%				1/3/{\frac{1}{2}}
		%				3/4/{\frac{1}{2}},
		%				4/5/{\frac{1}{5}}
		%			}
		%			\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			0/1/{1},
			0/2/{3},
			0/3/{8},
			1/2/{1},
			2/3/{2},
			2/6/{7},	
			3/6/{4},
			4/7/{7},
			5/1/{2},
			5/4/{3},
			5/7/{5},
			6/5/{2},
			6/7/{9}	
		}
		\path[edge] (\source) to node[weight]{$\weight$} (\dest);
		
		
		%			\foreach \source/ \dest /\weight in {
		%				4/4/{\frac{4}{5}}
		%			}
		%			\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
		
		% Draw initial state
		\path[edge] (-0.5,0) to (0);
		
		%\path pic[draw, angle radius=9mm, angle eccentricity=1.2, "xyz"] {angle = 1--0--2};
		\end{tikzpicture}
	\end{center}
	\pause
	\item Markov Decision Process (MDP)
	\pause
	\item Task
	\begin{itemize}
		\item Give a strategy to reach the goal with minimal \textit{expected} accumulated weights!
	\end{itemize}
\end{itemize}
\end{frame}

\section{Essential Definitions}

\begin{frame}
\begin{itemize}
	\item MDP
	\item Expectation
	\item Conditional Expectation
	\item Variance-penalized Expectation
	\item schedulers, kind of schedulers...
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{The classic stochastic shortest path problem}
	\begin{itemize}
		\item given:
		\begin{itemize}
			\item a single goal state
			\item positive cycle condition: There is no cycle with $\sum{wgt} \geq 0$
			\item goal is reachable from each state
		\end{itemize}
		\item goal: Maximize the expected accumulated weight until reaching goal state.
		\item Well known for a long time:
		\begin{itemize}
			\item There exists an optimal memoryless deterministic scheduler $\mathfrak{S}$.
			\item $\mathfrak{S}$ is computable by solving a LP
			\item iterative algorithm:
			\begin{itemize}
				\item start at any feasible scheduler
				\item iterative improvement
				\item stop at an optimal vertex of the LP (corresponding to some MD scheduler)
			\end{itemize}
		\end{itemize}
	\end{itemize}
\end{frame}%[3]

\section{The classic stochastic shortest path problem}

\begin{frame}
\frametitle{The classic stochastic shortest path problem}
\begin{itemize}
	\item Can we do it better?
	\item YES! - using \textbf{spider construction}!
	\item Assume furthermore:
	\begin{itemize}
		\item $\mathcal{M}$ is an MDP with arbitrary integer weights
	\end{itemize}
	\item The following can be solved in polynomial time:
	\begin{itemize}
		\item Check: $\mathbb{E}_{\mathcal{M},s}^{inf}(\boxplus \mathrm{goal}) > - \infty$?
		\item Compute $\mathbb{E}_{\mathcal{M},s}^{inf}$ if it is finite
	\end{itemize}

\end{itemize}
\end{frame}%[1]

\begin{frame}
	\frametitle{Spider Construction}
	\begin{itemize}
		\item Idea: construct a new MDP $\mathcal{N}$ from the given MDP $\mathcal{M}$
		\item Pick a 0-BSCC $\mathcal{E}$ of $\mathcal{M}$ and some vertex $s_0$ in $\mathcal{E}$.
		\item $\mathcal{M} \mapsto \mathcal{N} \coloneqq \mathrm{Spider}_{\mathcal{E}, s_0}(\mathcal{M})$
		\item The spider construction is done by applying the following steps:
		\begin{enumerate}
			\item Remove all actions $(s, s_\alpha) \in \mathcal{E}$
			\item Add actions $(s, \tau)$ for all $s\in \mathcal{E} \setminus \{s_0\}$ such that
			\begin{itemize}
				\item $P_{\mathcal{N}}(s,\tau,s_0) \coloneqq 1$
				\item $wgt_{\mathcal{N}}(s,\tau) \coloneqq wgt (s, s_0)$
			\end{itemize}
			\item For each $s\in \mathcal{E}\setminus\{s_0\}$ and $\beta \in \mathrm{Act}_{\mathcal{M}}(s)\setminus\{\alpha_s\}$ let us replace $(s,\beta)$ by $(s_0,\beta)$ where
			\begin{itemize}
				\item $P_{\mathcal{N}}(s_0,\beta,u) \coloneqq P_{\mathcal{M}}(s,\beta,u)$
				\item $wgt_{\mathcal{N}}(s_0,\beta) + wgt (s, s_0) = wgt_{\mathcal{M}}(s,\beta)$
			\end{itemize}
		\end{enumerate}
	\end{itemize}

\end{frame}

\begin{frame}
	\frametitle{Classification of paths}
	A path $\pi \in \mathrm{InfPaths}(\mathcal{M})$ is called 
	\begin{itemize}
		\item pumping $\ratio\Leftrightarrow \liminf_{n \to \infty}(\mathrm{wgt}(\mathrm{pref(\pi, n)})) = \infty$
		\item \begin{tabular}{c}(positively) \\ negatively \end{tabular} weight divergent $\ratio\Leftrightarrow$ \begin{tabular}{c} $\limsup_{n \to \infty}$ \\ $\liminf_{n \to \infty}$ \end{tabular} $=$ \begin{tabular}{c} ${\infty}$ \\ ${-\infty}$ \end{tabular}
		\item gambling $\ratio\Leftrightarrow$ $\pi$ is positively and negatively weight divergent
		\item bounded from below $\ratio\Leftrightarrow \liminf_{n \to \infty} \mathrm{wgt}(\mathrm{pref}(\pi,n)) \in \mathbb{Z}$
	\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Classification of end components}
We distinguish end components by the following types
\begin{itemize}
	\item pumping ECs: $\exists \text{ scheduler } \mathfrak{S}: \mathbb{Pr}(\pi \text{ is pumping}) = 1$
	\item \begin{tabular}{c}(positively) \\ negatively \end{tabular} weight divergent ECs: $\exists \text{ scheduler } \mathfrak{S}: \mathbb{Pr}(\pi \text{ is }$ \begin{tabular}{c}(positively) \\ negatively \end{tabular} weight divergent $) = 1$
	\item gambling ECs: $\mathbb{E}(\mathrm{MP}) = 0$ and it is positively and negatively weight divergent
	\item bounded EC: There exists an upper bound and a lower bound
\end{itemize}
\end{frame}


\section{Different variants of the stochastic shortest path problem}

\begin{frame}
	Imagine to not reach goal with probability 1.
	\begin{itemize}
		\item maximal conditional expected auccumulated reward
		\item partial expected accumulated reward.
	\end{itemize}
\end{frame}

\begin{frame}
	\begin{tabular}{|p{5cm}|p{5cm}|}
		\hline
		conditional expectation & partial expectation \\ \hline
		$\mathbb{CE}$ & $\mathbb{PE}$ \\ \hline
		$\mathbb{CE} = \mathbb{E}(\boxplus \mathrm{goal}\mid \diamondsuit \mathrm{goal})$ & $\pi \nvDash \diamondsuit\mathrm{goal} \Rightarrow \mathrm{wgt}(\pi)\coloneqq0$ \\ \hline
		good approximation for \newline maximizing probability and reward until goal & may lead to quite high $\mathbb{CE}$ paired with \newline low probability of reaching goal \\ \hline
		
	\end{tabular}
\end{frame}

\begin{frame}
	\frametitle{conditional expected accumulated reward}
	Given:
	\begin{itemize}
		\item MDP $\mathcal{M}$ with non-negative integer weights
		\item two sets of states $F, G \subseteq \mathrm{States}(\mathcal{M})$
	\end{itemize}
	\begin{definition}
		\[
		\mathbb{CE}^{max} \coloneqq \sup_{\mathfrak{S} \in S}(\mathcal{E}_{\mathcal{M}, s_init}^{\mathfrak{S}}(\boxplus F \mid \diamondsuit G))
		\]
		where $S$ is the set of schedulers: %\in \mathrm{schedulers}(\mathcal{M})
		\[
		S \coloneqq \{\mathfrak{S} \mid \mathbb{Pr}_{\mathcal{M},s_init}^{\mathfrak{S}}(\diamondsuit G) > 0 \land \mathbb{Pr}_{\mathcal{M},s_init}^{\mathfrak{S}}(\diamondsuit F \mid \diamondsuit G) = 1\}
		\]
		
	\end{definition}
	
\end{frame}

\begin{frame}
\frametitle{results about conditional expected accumulated rewards}
\begin{itemize}
	\item There is a \textbf{PTime algorithm} to decide: \texttt{Is $\mathbb{CE}^{max}$ finite?}
	\item There is a \textbf{pseudo-PTime algorithm} to \texttt{calculate an upperbound $\mathbb{CE}^{ub} \geq \mathbb{CE}^{max}$}
	\item \textit{If we have $F=G$ and $\forall s \in \mathrm{States}(\mathcal{M}): s \vDash \exists \diamondsuit G \Rightarrow \mathbb{Pr}_{\mathcal{M},s}^{min}(\diamondsuit G) > 0$ } there is a \textbf{PTime algorithm} to \texttt{calculate an upperbound $\mathbb{CE}^{ub} \geq \mathbb{CE}^{max}$}
	\item The problem \texttt{Decide if $\mathbb{CE}^{max} \bowtie t$} where we have
	\begin{itemize}
		\item $t\in \mathbb{Q}\dots$ some rational threshold
		\item $\bowtie \in \{<\leq,\geq,>\}$
	\end{itemize} is \textbf{PSPACE-hard}, solvable in \textbf{ExpTime} and \textit{for acyclic MDPs} \textbf{PSPACE-complete}
	\item In \textbf{ExpTime} we can \texttt{compute $\mathbb{CE}^{max}$ together with an optimal scheduler}
\end{itemize}

\end{frame}


\section{Keep an eye on the variance}




\begin{comment}


\begin{frame}
	\begin{itemize}
		\item endliche Pfade (konkreter Startknoten, Menge von Zielknoten)
		\item Kantengewichte
		\begin{center}%#2
			\begin{tikzpicture}[auto,swap,scale=3]
			
			% First we draw the vertices
			\foreach \pos/\name in {{(0,0)/1}, {(1,0)/3}, {(2,0)/4}, {(0,1)/2}}
			\node[vertex] (\name) at \pos {$\name$};
			
			% First we draw the vertices
			\foreach \pos/\name in {{(1,1)/6}, {(2,1)/5}}
			\node[target] (\name) at \pos {$\name$};
			
			% Connect vertices with edges and draw weights
			\foreach \source/ \dest /\weight in {
				1/2/{\frac{1}{2}:4},
				2/6/{1:2},
				5/6/{1:3},
				6/5/{1:7}
			}
			\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
			
			% Connect vertices with edges and draw weights
			\foreach \source/ \dest /\weight in {
				1/3/{\frac{1}{2}:5},
				3/4/{\frac{1}{2}:2},
				4/5/{\frac{1}{5}:3}
			}
			\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
			
			% Connect vertices with edges and draw weights
			\foreach \source/ \dest /\weight in {
				3/2/{\frac{1}{4}:5},
				3/5/{\frac{1}{4}:3}
			}
			\path[edge] (\source) to node[weight]{$\weight$} (\dest);
			
			\foreach \source/ \dest /\weight in {
				4/4/{\frac{4}{5}:2}
			}
			\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
			
			% Draw initial state
			\path[edge] (-0.5,0) to (1);
			
			\end{tikzpicture}
		\end{center}
		\pause		
		\item Berechnung von Varianzen akkumulierter Kantengewichte
		\item Literaturhinweis: Reward Variance in Markov Chains: A Calculational Approach (Tom Verhoeff, May 2004)
	\end{itemize}
\end{frame}

\section{Grundlagen}

\subsection{Wahrscheinlichkeitstheorie}


\newcommand{\probspace}{diskreter Wahr\-schein\-lich\-keits\-raum}
\newcommand{\probspacen}{diskreten Wahr\-schein\-lich\-keits\-raum}
\newcommand{\probspaceexraw}{(\Omega, P)}
\newcommand{\probspaceex}{$(\Omega, P)$}
\newcommand{\rvar}{Zufallsvariable}

\begin{frame}
\begin{definition}[\probspace{}] \label{def-probspace}
	\hspace{-0.5em} Wir nennen ein Paar \probspaceex{} einen \probspacen{}, wenn $\Omega$ eine abzählbare Menge ist und $P : \Omega \to [0,1] $ eine Funktion mit
	\begin{equation}
	\sum_{\omega \in \Omega} P(\omega) = 1 \text{.}
	\end{equation} Wir nennen $\Omega$ in diesem Zusammenhang auch Ergebnismenge und $P$ eine Wahr\-schein\-lich\-keitsverteilung auf $\Omega$.
\end{definition}
\pause
\begin{definition}[\rvar{}] \label{def-rvar}
	Sei \probspaceex{} ein \probspace{}. Eine Funktion 
	\begin{equation}
	X : \Omega \to \mathbb{R}
	\end{equation} heißt \rvar{} auf \probspaceex{}. \textcolor{lightgray}{Wir nennen $X$ auch kurz \rvar{}, falls der Kontext \probspaceex{} klar ist.}
\end{definition}
\end{frame}

\newcommand{\expect}{Erwartungswert}
\newcommand{\mexp}{\mathcal{E}}

\begin{frame}
	\begin{definition}[\expect{}] \label{def-expect}
		Sei \probspaceex{} ein \probspace{} und $X$ eine \rvar{} auf \probspaceex{}. Mit
	\begin{equation}
		\mathcal{E}_{\probspaceexraw{}}(X) \coloneqq \sum_{\omega \in \Omega}{P(\omega) \cdot X(\omega)}
	\end{equation}
		bezeichnen wir den \expect{} von $X$ auf \probspaceex{}. \textcolor{lightgray}{Sollte der Kontext \probspaceex{} klar sein, schreiben wir auch kurz $\mathcal{E}(X)$.}
	\end{definition}
\end{frame}

\begin{frame}
	\begin{lemma}[Linearität des \expect{}es] \label{lem-explin}
		Seien $X$, $Y$ Zufallsvariablen auf demselben diskreten Wahrscheinlichkeitsraum, $c,d \in \mathbb{R}$. Dann gilt:
		\begin{equation}
		\mathcal{E}(X + cY + d) = \mathcal{E}(X) + c \mathcal{E}(Y) + d \label{eq-linearity}
		\end{equation}
		Dabei ist  $X + cY + d$ die übliche Notation für die \rvar{} gegeben durch $Z : \Omega \to \mathbb{R} : \omega \mapsto X(\omega) + c \cdot Y(\omega)+ d$.
	\end{lemma}

%	\begin{proof}
%		\begin{align}
%			\mathcal{E}(X + cY + d) & = \sum_{\omega \in \Omega}{P(\omega) \cdot (X + cY + d)(\omega) } \nonumber \\
%			& = \sum_{\omega \in \Omega}{P(\omega) \cdot X(\omega) + c \cdot P(\omega) \cdot Y(\omega) + d \cdot P(\omega)} \nonumber \\
%			& = \mathcal{E}(X) + c \mathcal{E}(Y) + d \nonumber
%		\end{align}
%	\end{proof}

\end{frame}

\newcommand{\var}{Varianz}
\newcommand{\mvar}{\mathcal{V}\!ar}
\newcommand{\cov}{Kovarianz}
\newcommand{\mcov}{\mathcal{C}\!ov}

\begin{frame}
	\begin{definition}[\var]\label{def-var}
		Sei \probspaceex{} ein \probspace{} und $X$ eine \rvar{} auf \probspaceex{}. Mit
		\begin{equation}
		\mvar_{\probspaceexraw{}}(X) \coloneqq  \mathcal{E}_{\probspaceexraw{}}\left(\left(X - \mathcal{E}_{\probspaceexraw{}} (X)\right)^{2}\right)
		\end{equation}
		bezeichnen wir die \var{} von $X$ auf  \probspaceex{}. \textcolor{lightgray}{Sollte der Kontext \probspaceex{} klar sein, schreiben wir kurz $\mvar(X)$.}
	\end{definition}
%\end{frame}
%\begin{frame}
	\begin{definition}[\cov]\label{def-cov}
		Seien \probspaceex{} ein \probspace{} und $X, Y$ \rvar n auf \probspaceex{}. Die \cov{} $\mcov{}_{\probspaceexraw}(X,Y)$ ist definiert durch:
		\begin{equation}
		\mcov{}_{\probspaceexraw}(X,Y) \coloneqq \mathcal{E} \Big( \big(X - \mathcal{E}(X)\big)\big(Y - \mathcal{E}(Y) \big)\Big)
		\end{equation}
	\end{definition}

\end{frame}

\begin{frame}
	\begin{proposition}
		Die \var{} ist ein Spezialfall der \cov{}:
		\[\mvar_{\probspaceexraw}(X) = \mcov{}_{\probspaceexraw}(X,X)\]
	\end{proposition}

	\begin{lemma}\label{lemma-cov-exp}
		Seien $X$ und $Y$ \rvar{}n auf demselben diskreten Wahrscheinlichkeitsraum{}. Dann gilt:
		\begin{align*}
		\mcov{}(X,Y) = \mathcal{E}(XY) - \mathcal{E}(X)\mathcal{E}(Y) \\
		\onslide<2->{
		\mvar(X) = \mathcal{E}(X^{2}) - \mathcal{E}\left(X\right)^{2} \\
		}
		\onslide<3->{
		\mvar(cX + d) = c^2\cdot\mvar(X)
		}
		\end{align*}
	\end{lemma}
\end{frame}


\begin{frame}
	\begin{proof}
		\begin{align*}
		\mcov{}(X,Y) & = \mathcal{E}\big( \left(X - \mathcal{E}(X)\right)\left(Y - \mathcal{E}(Y)\right)\big) \\
		& = \mathcal{E}\big(XY - X \mathcal{E}(Y) - Y \mathcal{E}(X) + \mathcal{E}(X)\mathcal{E}(Y)\big) \\
		& = \mathcal{E}(XY) - 2 \mathcal{E}(X) \mathcal{E}(Y) + \mathcal{E}(X) \mathcal{E}(Y) \\
		& = \mathcal{E}(XY) - \mathcal{E}(X)\mathcal{E}(Y) \\
		\end{align*}
	\end{proof}
\end{frame}
\begin{frame}
\begin{proof}
	\begin{align*}
	\mvar(cX + d) & = \mathcal{E}\Big(\big(cX + d - \mathcal{E}(cX + d)\big)^2\Big) \\
	& = \mathcal{E}\Big(\big(cX + d - c\mathcal{E}(X) - d\big)^2\Big) \\
	& = \mathcal{E}\Big(c^2 \cdot \big(X - \mathcal{E}(X) \big)^2\Big)\\
	& = c^2 \cdot \mathcal{E}\Big( \big(X - \mathcal{E}(X) \big)^2\Big) \\
	& = c^2 \cdot \mvar(X)
	\end{align*}
\end{proof}
\end{frame}

%\begin{frame}
%	\begin{korollar}
%		Sei $X$ eine Zufallsvariable und $c \in \mathbb{R}$. Dann gilt:
%		\begin{equation}
%		\mathcal{E}\left((c+X)^2\right) = (c+ \mathcal{E}(X))^2 + \mvar(X)
%		\end{equation}
%	\end{korollar}
%\begin{proof}
%	\begin{align*}
%		\mvar(Y) &= \mathcal{E}\left(Y^{2}\right) - \left(\mathcal{E}\left(Y\right)\right)^{2}\\
%		\mvar(X+c) &= \mathcal{E}\left((X+c)^{2}\right) - \left(\mathcal{E}\left(X+c\right)\right)^{2}\\
%		\mvar(X) = \mvar(X+c) &= \mathcal{E}\left((X+c)^{2}\right) - \left(\mathcal{E}\left(X\right)+c\right)^{2}\\
%	\end{align*}
%\end{proof}
%\end{frame}

\subsection{\mc{}n}
\newcommand{\mcex}{$M = (Q, P, I)$}

\begin{frame}
	\begin{definition}[\mc]\label{def-mc}
		Eine \mc{} ist ein Tupel $(Q, P, I)$ mit den Eigenschaften
		\begin{enumerate}[(a)]
			\item $Q$ ist eine abzählbare Menge.
			\pause
			\item $P : Q \times Q \to [0,1]$ mit der Eigenschaft $\forall q \in Q : \sum_{q' \in Q}{P(q,q') = 1}$.
			\pause
			\item $I : Q \to [0,1]$ ist eine Wahrscheinlichkeitsverteilung auf $Q$.
		\end{enumerate}
		\textcolor{lightgray}{
		Die Bilder von $P$ nennen wir auch Transitionswahrscheinlichkeiten und definieren mit welcher Wahrscheinlichkeit, nämlich $P(q,q')$ vom aktuellen Zustand $q$ in den Zustand $q'$ übergegangen wird. $I$ ist die initiale Verteilung, welche definiert, mit welcher Wahrscheinlichkeit ein Zustand als Startzustand gewählt wird.}
	
		\pause
		Wir beschränken uns im Folgenden auf \textbf{endliche \mc{}n}, d.h. \textbf{$|Q| < \infty$}.
	\end{definition}
\end{frame}

\begin{frame}
	\begin{center}%#2
		\begin{tikzpicture}[auto,swap,scale=3]
		
		% First we draw the vertices
		\foreach \pos/\name in {{(0,0)/1}, {(1,0)/3}, {(2,0)/4}, {(0,1)/2}, {(1,1)/6}, {(2,1)/5}}
		\node[vertex] (\name) at \pos {$\name$};
		
		% First we draw the vertices
		\foreach \pos/\name in {}
		\node[target] (\name) at \pos {$\name$};
		
		% Connect vertices with edges and draw weights
	\foreach \source/ \dest /\weight in {
		1/2/{\frac{1}{2}},
		2/6/{1},
		5/6/{1},
		6/5/{1}
	}
	\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
	
	% Connect vertices with edges and draw weights
	\foreach \source/ \dest /\weight in {
		1/3/{\frac{1}{2}},
		3/4/{\frac{1}{2}},
		4/5/{\frac{1}{5}}
	}
	\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
	
	% Connect vertices with edges and draw weights
	\foreach \source/ \dest /\weight in {
		3/2/{\frac{1}{4}},
		3/5/{\frac{1}{4}}
	}
	\path[edge] (\source) to node[weight]{$\weight$} (\dest);
	
	\foreach \source/ \dest /\weight in {
		4/4/{\frac{4}{5}}
	}
	\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
	
	% Draw initial state
	\path[edge] (-0.5,0) to (1);
		
		\end{tikzpicture}
	\end{center}
\end{frame}

\newcommand{\gpath}{Pfad}
\newcommand{\pfin}{\mathrm{Paths}}%_{fin}

\begin{frame}
	\begin{definition}[\gpath]\label{def-path}
		Sei \mcex{} eine \mc{}. Die Menge aller endlichen \gpath e in $M$ sei definiert durch
		\begin{equation*}
		\pfin(M) \coloneqq \{p \in Q^{k} \mid k \in \mathbb{N}_{>0} \land \forall 0 \leq i < k : P(p_i,p_{i+1}) > 0\}
		\end{equation*}
		\pause
		Notationen für $k \in \mathbb{N}_{>0}, p \in Q^k$:
		\begin{itemize}
			\item $|p| \coloneqq k$
			\pause
			\item $p = (p_0,p_1, \dots, p_{k-1})$
			\pause
			\item $$ \text{Wahrscheinlichkeit: } \mathrm{\tilde{P}}(p) \coloneqq \prod_{i = 0}^{|p| - 2}{P(p_i,p_{i+1})}$$ %eines $p \in Q^k$ $\mathrm{\tilde{P}}(p)$
		\end{itemize}
		\pause
		Eigenschaften:
		\begin{itemize}
			\item $|p| = 1 \implies \mathrm{\tilde{P}}(p) = 1$
			\pause
			\item $k \in \mathbb{N}_{>0}, p \in Q^k \setminus \pfin(M) \implies \mathrm{\tilde{P}}(p) = 0$
			\pause 
			\item $\mathrm{\tilde{P}}$ ist die eindeutige Fortsetzung von $P$.
		\end{itemize}
	\end{definition}
\end{frame}

\newcommand{\reward}{Gewichtsfunktion}

\begin{frame}
	\begin{definition}[\reward (engl. reward)]
		Sei \mcex{} eine \mc{}. Eine \reward{} auf $M$ ist eine Abbildung
		\begin{equation*}
		R : Q \times Q \to \mathbb{R}\text{.}
		\end{equation*} 
	\end{definition}
	\pause
	Eindeutige Fortsetzung auf Pfade durch Aufsummierung:
	\begin{equation*}
	\mathrm{\tilde{R}} : \bigcup_{k \in \mathbb{N}_{>0}}{Q^k} \to \mathbb{R} : p \mapsto \sum_{i = 0}^{|p| - 2}{R(p_i,p_{i+1})}
	\end{equation*}
\end{frame}

\begin{frame}
	\begin{definition}\label{def-path-to}
		Sei 
		\begin{itemize}
			\item \mcex{} eine \mc{}, \pause
			\item  $s \in Q$ ein beliebiger Zustand, genannt Startzustand \pause
			\item und $A \subseteq Q$ eine Menge von Zielzuständen.
		\end{itemize}
		\pause 
		Wir definieren Menge der Pfade, welche in $s$ starten und in $A$ enden, jedoch $A$ nicht zwischenzeitlich schon erreichen: \pause
		\begin{align*}
		\pfin_{s \rightarrow A}(M) \coloneqq \big\{ &p \in \pfin(M) \mid \\
		&p_0 = s \;\land \\
		&p_{|p|-1} \in A\; \land \\
		&\forall i < |p| - 1 : p_i \notin A \big\}
		\end{align*}
		
	\end{definition}
\end{frame}


\begin{frame}
	\begin{itemize}
		\item \begin{center}
			\bfseries Ziel: \expect{}e, \var{}en akkumulierter Kantengewichte auf Pfaden berechnen
		\end{center}
		\vspace{2ex}
		\pause
		\item 	Seien $s,q \in Q$ zwei Zustände und $\emptyset \neq A \subseteq Q$. Wir setzen voraus:
		\[
		\pfin_{s \rightarrow \{q\}}(M) \neq \emptyset  \quad \Rightarrow \quad \pfin_{q \rightarrow A}(M) \neq \emptyset \text{.}
		\] \pause
		\item Fast sicher bei Start in $s$: nach endlich vielen Schritten in $A$ ankommen. \pause
		\vspace{2ex}
		\item $\implies$ Das Tupel
		\[
		(\mathrm{Paths}_{s \rightarrow A}(M), P)
		\] ist ein \probspace{}. 
	\end{itemize}	
\end{frame}

\begin{frame}
		Gegeben sei eine \mc{} \mcex{} mit
		\begin{align*}
		Q &=\{1,2,3,4,5,6\} \\[2ex]
		\onslide<2->{
		P &=\begin{pmatrix}
		0 & 0,5 & 0,5 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 & 0 & 1 \\
		0 & 0,25 & 0 & 0,5 & 0,25 & 0 \\
		0 & 0 & 0 & 0,8 & 0,2 & 0 \\
		0 & 0 & 0 & 0 & 0 & 1 \\
		0 & 0 & 0 & 0 & 1 & 0 \\
		\end{pmatrix}} \\[2ex]
		\onslide<3->{
		I &=\begin{pmatrix} 1 & 0 & 0 & 0 & 0 & 0\end{pmatrix}^\intercal
		}
		\end{align*}
		
		
		\begin{itemize}
			\onslide<3->{\item ein eindeutiger Startzustand}
			\onslide<4->{
			\item Zielzustände: \qquad $\{5,6\}$
			\item Gewichtsfunktion $R$
			\item darstellbar als Graph
			}
		\end{itemize}
	

\end{frame}

\begin{frame}		
		\begin{center}%#2
		\textbf{ Beschriftung der Kanten $(i,j)$ in der Form $P(i,j) : R(i,j)$}
		\vspace{4ex}
		\textcolor{white}{ }
		\begin{tikzpicture}[auto,swap,scale=3]
		
		% First we draw the vertices
		\foreach \pos/\name in {{(0,0)/1}, {(1,0)/3}, {(2,0)/4}, {(0,1)/2}}
		\node[vertex] (\name) at \pos {$\name$};
		
		% First we draw the vertices
		\foreach \pos/\name in {{(1,1)/6}, {(2,1)/5}}
		\node[target] (\name) at \pos {$\name$};
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			1/2/{\frac{1}{2}:4},
			2/6/{1:2},
			5/6/{1:3},
			6/5/{1:7}
		}
		\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			1/3/{\frac{1}{2}:5},
			3/4/{\frac{1}{2}:2},
			4/5/{\frac{1}{5}:3}
		}
		\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			3/2/{\frac{1}{4}:5},
			3/5/{\frac{1}{4}:3}
		}
		\path[edge] (\source) to node[weight]{$\weight$} (\dest);
		
		\foreach \source/ \dest /\weight in {
			4/4/{\frac{4}{5}:2}
		}
		\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
		
		% Draw initial state
		\path[edge] (-0.5,0) to (1);
		
		\end{tikzpicture}
	\end{center}
	\pause
	Frage nach Erwartungswert und Varianz von $R$ im diskreten Wahrscheinlichkeitsraum $(\mathrm{Paths}_{1 \rightarrow \{5,6\}}(M), P)$
	
\end{frame}
\newcommand{\exres}{10}
\begin{frame}
	\onslide<1->{
	\begin{center}
		\begin{tikzpicture}[auto,swap,scale=3]
		
		% First we draw the vertices
		\foreach \pos/\name in {{(0,0)/1}, {(1,0)/3}, {(2,0)/4}, {(0,1)/2}}
		\node[vertex] (\name) at \pos {$\name$};
		
		% First we draw the vertices
		\foreach \pos/\name in {{(1,1)/6}, {(2,1)/5}}
		\node[target] (\name) at \pos {$\name$};
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			1/2/{\frac{1}{2}:4},
			2/6/{1:2},
			5/6/{1:3},
			6/5/{1:7}
		}
		\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			1/3/{\frac{1}{2}:5},
			3/4/{\frac{1}{2}:2},
			4/5/{\frac{1}{5}:3}
		}
		\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			3/2/{\frac{1}{4}:5},
			3/5/{\frac{1}{4}:3}
		}
		\path[edge] (\source) to node[weight]{$\weight$} (\dest);
		
		\foreach \source/ \dest /\weight in {
			4/4/{\frac{4}{5}:2}
		}
		\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
		
		% Draw initial state
		\path[edge] (-0.5,0) to (1);
		
		\end{tikzpicture}
	\end{center}
	}
\only<1->{
	\begin{equation*}
	\Omega \coloneqq \mathrm{Paths}_{1 \rightarrow \{5,6\}}(M) = \big\{126,1326,135\big\} \; \cup \big\{134^n5 \in Q^{n+3} \mid n\geq 1\big\}
	\pause
	\end{equation*}
}
\begin{overlayarea}{\textwidth}{\textheight}
\only<2>{
	\vspace{-2ex}
	\begin{align*}
	\mathcal{E}(R) & = \sum_{p \in \Omega}{P(p) \cdot R(p)}\\
	& = \frac{1}{2}\cdot 6_{\scriptscriptstyle [126]} + \frac{1}{8}\cdot 12_{\scriptscriptstyle [1326]} + \frac{1}{8}\cdot 8_{\scriptscriptstyle [135]} + \sum_{n = 0}^{\infty}{\frac{1}{20}\cdot\left(\frac{4}{5}\right)^n \cdot (10 + 2n)}_{\scriptscriptstyle [134^n5]} \\
	& = \exres{}
	\end{align*}
}
\only<3>{
	\begin{align*}
	\mvar(R) & = \mathcal{E}\big((R - \exres{})^2\big) = \frac{1}{2}\cdot (6 - \exres)^2 + \frac{1}{8}\cdot (12-\exres)^2 +\\
	& +  \frac{1}{8}\cdot (8-\exres)^2 + \sum_{n = 0}^{\infty}{\frac{1}{20}\cdot\left(\frac{4}{5}\right)^n \cdot (10 + 2n - \exres)^2}
	\end{align*}
}
\only<4>{
	\begin{align*}
	\mvar(R) & = \mathcal{E}\big((R - \exres{})^2\big) \\
	& = 9 + \frac{1}{5}\sum_{n = 0}^{\infty}{\left(\frac{4}{5}\right)^n \cdot n^2} \\
	& = 45
	\end{align*}
}
\only<5>{
	\vspace{2ex}
	Eine Berechnung nach Definition wird wesentlich umständlicher, wenn es unendlich viele Kreise gibt
}
\end{overlayarea}
\end{frame}

\begin{comment}
	
\begin{frame}
%\begin{overlayarea}{\textwidth}{\textheight}
	\begin{itemize}
%		 \only<1-3>{ 
		 	\item Wir berechneten $\mvar(R) = \mathcal{E}\big((R - \exres{})^2\big) = \dots$%}
%		 \only<1-3>{ 
			\item Sei  $X \coloneqq (R-\exres)^2$%}
			\pause
		%\only<2-3>{ 
		\item Aber %}
	\end{itemize}
	%\only<3>{
	\[
	X : \mathrm{Paths}_{1 \rightarrow \{5,6\}}(M) \to  \mathbb{R} : p \mapsto (R(p) - \exres)^2
	\]
	erfüllt i.A. nicht die Eigenschaft der eindeutigen Fortsetzung von Kanten zu Pfaden:
	\[
	\forall n \in \mathbb{N}, p \in Q^n : n>1 \Rightarrow X(p) = \sum_{i=0}^{n-2}{X(p(i),p(i+1))}
	\]
	%}
	\pause
	\begin{itemize}
		\item Beispiel: $X(1,3) + X(3,2) = 25 + 25 \neq 0 = X(132)$
	\end{itemize}
%\end{overlayarea}
\end{frame}

\newcommand{\mcexgr}{	\begin{center}
		\begin{tikzpicture}[auto,swap,scale=3]
		
		% First we draw the vertices
		\foreach \pos/\name in {{(0,0)/1}, {(1,0)/3}, {(2,0)/4}, {(0,1)/2}}
		\node[vertex] (\name) at \pos {$\name$};
		
		% First we draw the vertices
		\foreach \pos/\name in {{(1,1)/6}, {(2,1)/5}}
		\node[target] (\name) at \pos {$\name$};
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			1/2/{\frac{1}{2}:4},
			2/6/{1:2},
			5/6/{1:3},
			6/5/{1:7}
		}
		\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			1/3/{\frac{1}{2}:5},
			3/4/{\frac{1}{2}:2},
			4/5/{\frac{1}{5}:3}
		}
		\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			3/2/{\frac{1}{4}:5},
			3/5/{\frac{1}{4}:3}
		}
		\path[edge] (\source) to node[weight]{$\weight$} (\dest);
		
		\foreach \source/ \dest /\weight in {
			4/4/{\frac{4}{5}:2}
		}
		\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
		
		% Draw initial state
		\path[edge] (-0.5,0) to (1);
		
		\end{tikzpicture}
\end{center}}

\begin{frame}
		\begin{itemize}
		\item Beispiel: $X(1,3) + X(3,2) = 25 + 25 \neq 0 = X(132)$
	\end{itemize} \pause
		\begin{center}
			\begin{tikzpicture}[auto,swap,scale=3]
			
			% First we draw the vertices
			\foreach \pos/\name in {{(0,0)/1}, {(1,0)/3}, {(2,0)/4}, {(0,1)/2}}
			\node[vertex] (\name) at \pos {$\name$};
			
			% First we draw the vertices
			\foreach \pos/\name in {{(1,1)/6}, {(2,1)/5}}
			\node[target] (\name) at \pos {$\name$};
			
			% Connect vertices with edges and draw weights
			\foreach \source/ \dest /\weight in {
				1/2/{\frac{1}{2}:4},
				2/6/{1:2},
				5/6/{1:3},
				6/5/{1:7}
			}
			\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
			
			% Connect vertices with edges and draw weights
			\foreach \source/ \dest /\weight in {
				1/3/{\frac{1}{2}:5},
				3/4/{\frac{1}{2}:2},
				4/5/{\frac{1}{5}:3}
			}
			\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
			
			% Connect vertices with edges and draw weights
			\foreach \source/ \dest /\weight in {
				3/2/{\frac{1}{4}:5},
				3/5/{\frac{1}{4}:3}
			}
			\path[edge] (\source) to node[weight]{$\weight$} (\dest);
			
			\foreach \source/ \dest /\weight in {
				4/4/{\frac{4}{5}:2}
			}
			\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
			
			% Draw initial state
			\path[edge] (-0.5,0) to (1);
			
			\end{tikzpicture}
		\end{center}
	\pause
	\[
	X : \mathrm{Paths}_{1 \rightarrow \{5,6\}}(M) \to  \mathbb{R} : p \mapsto (R(p) - \exres)^2
	\]
\end{frame}
%\ end{comment}

\section{Formale Herleitung eines Algorithmus}

\begin{frame}
	\begin{itemize}
		\item Wie berechnen wir Varianzen effizient?
		\item Wie berechnen wir \expect{}e effizient? \pause
		\item gegeben:
			\begin{itemize}
				\item \mc{} \mcex{}
				\item konkreter Startzustand $s \in Q$
				\item Zielmenge $\emptyset \neq A\subseteq Q$
				\item $A$ ist von jedem Knoten aus erreichbar.
			\end{itemize} \pause
		\item Beschreibung des Erwartungswertes durch die \expect{}e der Nachfolgeknoten \pause
		\item Wir betrachten im \probspacen{} $(\mathrm{Paths}_{s \rightarrow A}(M), P)$ den Erwartungswert $\mathcal{E}_{(\mathrm{Paths}_{s \rightarrow A}(M), P)}(R)$, im Folgenden kurz $\mathcal{E}_{s}(R)$: \pause
	\end{itemize}
	
	\begin{equation*}
	\mathcal{E}_{s}(R) = \sum_{p \in \mathrm{Paths}_{s \rightarrow A}(M)}{P(p) \cdot R(p)} 
	\end{equation*}
	


\end{frame}

\subsection{Berechnung von Erwartungswerten}


\begin{frame}
		
	\begin{equation*}
	\mathcal{E}_{s}(R) = \sum_{p \in \mathrm{Paths}_{s \rightarrow A}(M)}{P(p) \cdot R(p)} 
	\end{equation*}
	
	\begin{itemize}
		\item Fall 1: $s \in A$ \pause
		\begin{itemize}
			\item $|\mathrm{Paths}_{s \rightarrow A}(M)| = 1$ \pause
			\item eindeutiger Pfad $p$ mit $p = (s)$ \pause
			\item per Definition $P(p) = 1$ und $R(p) = 0$ \pause
		\end{itemize}
	\end{itemize}
	
	\begin{align*}
	\onslide<5->{\mathcal{E}_{s}(R) & = & 0 && \text{(falls $s \in A$)}\label{expect_trivial} \\}
	\onslide<6->{\mathcal{E}_{s}(R) & = & \sum_{t \in Q}{ P(s,t) \cdot \left(R(s,t) + \mathcal{E}_{t}(R) \right) } && \text{(falls $s \notin A$)}}
	\end{align*}
	\begin{itemize}
		\onslide<7->{\item ... ausgedrückt durch \expect{}e der Folgezustände}
	\end{itemize}

\end{frame}


\begin{frame}
	\begin{overlayarea}{\textwidth}{25ex}
	\only<6->{
		\begin{definition}
		Sei $Q$ eine Menge, $n\in \mathbb{N}, n>2$ und $p \in Q^n$, in folgenden Betrachtungen als Pfad aufgefasst. Dann bezeichnen wir mit $p_{\leftarrow 1}$ den Teilpfad von $p = (p_0, \dots, p_{n-1})$ ohne den ersten Knoten $p_0$:
		\begin{equation*}
		p_{\leftarrow 1} \coloneqq (p_1,p_2, \dots p_{n-1})
		\end{equation*}
	\end{definition}
}
	\onslide<1-5>{
		\begin{align*}
			\mathcal{E}_{s}(R) & = & \sum_{t \in Q}{ P(s,t) \cdot \left(R(s,t) + \mathcal{E}_{t}(R) \right) } && \text{(falls $s \notin A$)}
		\end{align*}
	}
	\begin{itemize}
		\onslide<1-5>{\item Woher?}
		\onslide<2-5>{ \item Fall 2: $s \notin A$
			\begin{itemize}
				\onslide<3-5>{\item $|\mathrm{Paths}_{s \rightarrow A}(M)| \geq 1$}
				\onslide<4-5>{\item kein trivialer Pfad: $\forall p \in \mathrm{Paths}_{s \rightarrow A}(M): |p| > 1$}
			\end{itemize}
		}
	\end{itemize}
	\end{overlayarea}
\begin{overlayarea}{\textwidth}{25ex}
\begin{align*}
\only<5->{\mathcal{E}_{s}(R)}
\only<5-7>{ &= \sum_{p \in \mathrm{Paths}_{s \rightarrow A}(M)}{P(p) \cdot R(p)} \\}
\only<5-7>{& = \sum_{p \in \mathrm{Paths}_{s \rightarrow A}(M)}{P(s,p_1) \cdot P(p_{\leftarrow 1}) \cdot (R(s,p_1) + R(p_{\leftarrow 1}))} \\} 
\only<7->{& = \sum_{t \in Q}{ P(s,t) \cdot \sum_{p' \in \mathrm{Paths}_{t \rightarrow A}(M)}{ P(p') \cdot (R(s,t) + R(p')) } } \\}
\only<8->{& = \sum_{t \in Q}{ P(s,t) \cdot \left(R(s,t) + \sum_{p' \in \mathrm{Paths}_{t \rightarrow A}(M)}{ P(p') \cdot R(p') } \right) } \\}
\only<9->{& = \sum_{t \in Q}{ P(s,t) \cdot \big(R(s,t) + \mathcal{E}_{t}(R) \big) } \label{expect_recursive} \\}
\end{align*}
\end{overlayarea}
\end{frame}


\begin{frame}
	Sei $\mu_s \in \mathbb{R}$ für alle $s \in Q$. \pause
	\begin{align*}
	\mu_{s} & = & 0 && \text{(falls $s \in A$)} \\
	\mu_{s} & = & \sum_{t \in Q}{ P(s,t) \cdot \left(R(s,t) + \mu_{t} \right) } && \text{(falls $s \notin A$)}
	\end{align*} \pause
	
	\begin{definition}\label{def-pmod}
		Sei \mcex{} eine endliche \mc, $A\subseteq Q$ eine Zielmenge. Dann bezeichnen wir mit $P_{\rightarrow A}$ die folgende Matrix:
		\begin{equation*}
		P_{\rightarrow A} : Q^2 \to [0,1] : \begin{cases}
		P(s,t) & \text{falls } s\notin A\\
		0 & \text{falls } s\in A
		\end{cases}
		\end{equation*}
	\end{definition}
	\pause

	\begin{equation*}
	\mu_s = \sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot \left(R(s,t) + \mu_{t} \right) }\text{,}
	\end{equation*}

\end{frame}


\begin{frame}
	Sei  $\mu = (\mu_s)_{s \in Q }$. \pause
	\begin{align*}
	\mu_s &= \sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot \left(R(s,t) + \mu_{t} \right) }\\
	& \iff \\
	\mu &= \left(\sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot R(s,t) }\right)_{s \in Q} + P_{\rightarrow A} \cdot \mu  \\
	\onslide<3>{& \iff \\
	(P_{\rightarrow A} - \mathbb{1}) \mu &= - \left(\sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot R(s,t) }\right)_{s \in Q}\label{les-exp-mat}}
	\end{align*}
\end{frame}


\begin{frame}
	\begin{satz}\label{th-unique}
		Sei \mcex{} eine endliche \mc, $A\subseteq Q$ eine Zielmenge, die von jedem Knoten aus erreichbar ist ($\forall s\in Q: \mathrm{Paths}_{s\rightarrow A}(M)\neq\emptyset$). 
		Dann ist die Matrix $D \coloneqq P_{\rightarrow A} - \mathbb{1}$ invertierbar.
	\end{satz} \pause
	\begin{partproof}
		\begin{enumerate}[(1)]
			\item $D$ invertierbar $\iff$  $Dx = 0, x \in \mathbb{R}^{Q}$ hat nur die Lösung $x=0$ \pause
			\item Angenommen $x \in \mathbb{R}^Q$ mit $x\neq 0$ erfüllt $Dx = 0$ \label{solneqzero} \pause
			\item O.B.d.A. $ \exists q \in Q : x_q > 0$ (Andernfalls betrachte $-x$!) \pause
			\item Sei $E \subseteq Q$ die Indexmenge aller maximalen Einträge von $x$: \label{maxindices}
			\[ e \in E :\Leftrightarrow \forall q \in Q : x_q \leq x_e \]
		\end{enumerate}
	\end{partproof}
\end{frame}

\begin{frame}
	\begin{proof}
		\begin{enumerate}[(1)]
			\setcounter{enumi}{3}
			\item Sei $E \subseteq Q$ die Indexmenge aller maximalen Einträge von $x$. \pause
			\item \label{targetzero} Für alle $s\in A$ folgt $x_s = 0$, denn:
			\[
			(Dx)_s = 0 \implies  \sum_{q\in Q}{(P_{\rightarrow A}- \mathbb{1})_{(s,q)} \cdot x_q} = -\sum_{q\in Q}{\mathbb{1}_{(s,q)} \cdot x_q} = 0
			\] \pause
			\item Sei $s \in E$ beliebig.
			\begin{enumerate}[(a)]
				\item $x_s > 0$ (wegen (\ref{solneqzero}) und (\ref{maxindices})) \pause
				\item $s\notin A$ (wegen \ref{targetzero}) \pause
				\item $(Dx)_s = 0 \implies  \sum_{q\in Q}{(P_{\rightarrow A}- \mathbb{1})_{(s,q)} \cdot x_q} = 0$ \pause
				\item Daher $\sum_{q\in Q}{P_{(s,q)} \cdot x_q} = x_s$. \pause
				\item $\forall q\in Q: (P(s,q) > 0 \Rightarrow x_q = x_s)$ \pause
			\end{enumerate}
			\item $s \in E \land P(s,t)>0 \implies t \in E$ \pause
			\item Aber $A$ ist von jedem $s\in E$ erreichbar, $E \neq \emptyset$. Wir erhalten einen Widerspruch. 
		\end{enumerate}	
	\end{proof}
\end{frame}

\begin{frame}
	\begin{satz}[\expect{}e in \mc{}n]\label{th-exp}
		Seien \mcex{} eine \mc{} und $\emptyset \neq A\subseteq Q$ und sei von jedem Zustand $q\in Q$ ein Zustand in $A$ erreichbar. Dann ist der Vektor $\mu = (\mu_s)_{s \in Q }$ der Erwartungswerte akkumulierter Kantengewichte einer Gewichtsfunktion $R$ auf Pfaden von $s$ in die Menge $A$ die eindeutige Lösung des Gleichungssystems	
		\begin{equation*}
		(P_{\rightarrow A} - \mathbb{1}) \mu = - \left(\sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot R(s,t) }\right)_{s \in Q}\text{.}\label{les-exp-mat}
		\end{equation*}
	\end{satz}
\end{frame} \pause
\begin{proof}
	\begin{itemize}
		\item Die Erwartungswerte sind eine Lösung.
		\item Die Lösung ist eindeutig, da $P_{\rightarrow A} - \mathbb{1}$ invertierbar ist.
	\end{itemize}
\end{proof}

\begin{frame}
	Algorithmus zum Berechnen der Erwartungswerte:
	\begin{itemize}
		\item Berechne Vektor $- \left(\sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot R(s,t) }\right)_{s \in Q}\text{.}\label{les-exp-mat}$
		\item Löse das lineare Gleichungssystem mit geeignetem Standardverfahren
	\end{itemize}
\pause
Anmerkung:
	\begin{itemize}
		\item fix: \mc{}, Zielzustandsmenge
		\item Jeder Zustand einzeln als Startzustand betrachtet
	\end{itemize}
\end{frame}

\begin{frame}
	Unser Beispiel von vorhin...
		\begin{equation*}
		P_{\rightarrow \{5,6\}} - \mathbb{1} = \begin{pmatrix}
		-1 & 0,5 & 0,5 & 0 & 0 & 0 \\
		0 & -1 & 0 & 0 & 0 & 1 \\
		0 & 0,25 & -1 & 0,5 & 0,25 & 0 \\
		0 & 0 & 0 & -0,2 & 0,2 & 0 \\
		0 & 0 & 0 & 0 & -1 & 0 \\
		0 & 0 & 0 & 0 & 0 & -1 \\
		\end{pmatrix}\text{.}
		\end{equation*} \pause
		Als Inverses von $P_{\rightarrow \{5,6\}} - \mathbb{1}$ erhalten wir
		\begin{equation*}
		(P_{\rightarrow \{5,6\}} - \mathbb{1})^{-1} = \begin{pmatrix}
		-1 & -\frac{5}{8} & -\frac{1}{2} & -\frac{5}{4} & -\frac{3}{8} & -\frac{5}{8} \\
		0 & -1 & 0 & 0 & 0 & -1 \\
		0 & -\frac{1}{4} & -1 & -\frac{5}{2} & -\frac{3}{4} & -\frac{1}{4} \\
		0 & 0 & 0 & -5 & -1 & 0 \\
		0 & 0 & 0 & 0 & -1 & 0 \\
		0 & 0 & 0 & 0 & 0 & -1 \\
		\end{pmatrix}\text{.}
		\end{equation*}
\end{frame}

\begin{frame}
	\begin{align*}
	b &\coloneqq - \left(\sum_{t \in Q}{ P_{\rightarrow \{5,6\}}(s,t) \cdot R(s,t) }\right)_{s \in Q} \\
	&= \begin{pmatrix} -\frac{9}{2} & -2 & -3 & -\frac{11}{5} & 0 & 0 \end{pmatrix}^\intercal
	\end{align*} \pause 
	Wir erhalten in der Folge für das Produkt $\mu \coloneqq (P_{\rightarrow \{5,6\}} - \mathbb{1})^{-1}b$ den Vektor
	\begin{equation*}
	\mu = \begin{pmatrix} 10 & 2 & 9 & 11 & 0 & 0 \end{pmatrix}^\intercal\text{.}
	\end{equation*}
\end{frame}


\subsection{Berechnung von Kovarianzen}

\begin{frame}
	
	Seien wieder
	\begin{itemize}
		\item \mcex{} eine \mc{}, \pause 
		\item $s \in Q$, \pause
		\item $\emptyset \neq A \subseteq Q$ und \pause 
		\item sei von jedem Zustand $q\in Q$ ein Zustand in $A$ erreichbar. \pause
	\end{itemize}
	Seien nun $X, Y$ \reward{}en auf $M$. 
	\pause Wir betrachten die \cov{} $\mcov_s(X,Y) \coloneqq \mcov_{(\mathrm{Paths}_{s \rightarrow A}(M), P)}(X,Y)$: \pause
	\begin{equation*}
	\mcov_{s}(X,Y) = \mathcal{E}_{s}\big(\left(X - \mathcal{E}_{s} (X)\right)\left(Y - \mathcal{E}_{s} (Y)\right)\big) \pause
	\end{equation*}
	
	Es gilt:
	\begin{align*}
	\mcov_{s}(X,Y) = 0 && \text{(falls $s \in A$)}\label{cov_trivial}
	\end{align*}
\end{frame}


\begin{frame}
Falls $s \notin A$, besteht jeder Pfad $p \in \mathrm{Paths}_{s \rightarrow A}(M)$ aus mehr als einem Knoten und wir erhalten:

\begin{align*}
&\mcov_{s}(X,Y) \\
\onslide<2->{=& \sum_{p \in \mathrm{Paths}_{s \rightarrow A}(M)}{P(p) \cdot \big(\left(X(p) - \mathcal{E}_{s} (X)\right)\left(Y(p) - \mathcal{E}_{s} (Y)\right)\big)} \\}
\onslide<3->{=& \sum_{t \in Q}{ P(s,t) \sum_{p' \in \mathrm{Paths}_{t \rightarrow A}(M)}{ P(p') \cdot \begin{pmatrix}
		(X(s,t) + X(p') - \mathcal{E}_{s}(X)) \;\cdot \\
		\cdot \;(Y(s,t) + Y(p') - \mathcal{E}_{s}(Y)) \\
		\end{pmatrix}}} \\}
\onslide<4->{=& \sum_{t \in Q}{ P(s,t) \cdot \mathcal{E}_{t}\begin{pmatrix}
	\big( \alt<4>{X}{{\color{blue} X}} +\alt<4>{ X(s,t) - \mathcal{E}_{s}(X)}{{\color{green}  X(s,t) - \mathcal{E}_{s}(X)}}\big)\;\cdot \\
	\cdot\;\big(\alt<4>{Y}{{\color{red} Y}} + \alt<4>{Y(s,t) - \mathcal{E}_{s}(Y)}{{\color{yellow} Y(s,t) - \mathcal{E}_{s}(Y)}}\big) \\
	\end{pmatrix}} \\}
\onslide<5->{ =& \sum_{t \in Q}P(s,t) \cdot \begin{pmatrix}
	\mathcal{E}_{t}(\textcolor{blue}{X}\textcolor{red}{Y}) + \textcolor{blue}{\mathcal{E}_{t}(X)}\textcolor{yellow}{(Y(s,t) - \mathcal{E}_{s}(Y))} \; + \\
	+\; \textcolor{red}{\mathcal{E}_{t}(Y)}\textcolor{green}{(X(s,t) - \mathcal{E}_{s}(X))} \; + \\
	+\; \textcolor{green}{(X(s,t) - \mathcal{E}_{s}(X))}\textcolor{yellow}{(Y(s,t) - \mathcal{E}_{s}(Y))} \\
	\end{pmatrix} \\}
\end{align*}

\end{frame}


\begin{frame}
	\begin{align*}
	&\mcov_{s}(X,Y) \\
	\onslide<1->{ =& \sum_{t \in Q}P(s,t) \cdot \begin{pmatrix}
		\mathcal{E}_{t}(\textcolor{blue}{X}\textcolor{red}{Y}) + \textcolor{blue}{\mathcal{E}_{t}(X)}\textcolor{yellow}{(Y(s,t) - \mathcal{E}_{s}(Y))} \; + \\
		+\; \textcolor{red}{\mathcal{E}_{t}(Y)}\textcolor{green}{(X(s,t) - \mathcal{E}_{s}(X))} \; + \\
		+\; \textcolor{green}{(X(s,t) - \mathcal{E}_{s}(X))}\textcolor{yellow}{(Y(s,t) - \mathcal{E}_{s}(Y))} \\
		\end{pmatrix} \\}
	\onslide<2->{=& \sum_{t \in Q}P(s,t) \cdot \begin{pmatrix}
		\mathcal{E}_{t}(XY) - {\color{orange}\mathcal{E}_{t}(X)\mathcal{E}_{t}(Y)\;+} \\
		{\color{orange}+\;\mathcal{E}_{t}(X)\mathcal{E}_{t}(Y)} + \mathcal{E}_{t}(X)(Y(s,t) - \mathcal{E}_{s}(Y))\;+ \\
		+\; \mathcal{E}_{t}(Y)(X(s,t) - \mathcal{E}_{s}(X))\;+ \\
		+\; (X(s,t) - \mathcal{E}_{s}(X))(Y(s,t) - \mathcal{E}_{s}(Y)) \\
		\end{pmatrix}\\}
	\onslide<3->{=& \sum_{t \in Q}P(s,t) \cdot \Bigg( \mcov_{t}(X,Y) + \begin{pmatrix}
		\big(\mathcal{E}_{t}(X) + X(s,t) - \mathcal{E}_{s}(X)\big)\;\cdot \\
		\cdot\;\big(\mathcal{E}_{t}(Y) + Y(s,t) - \mathcal{E}_{s}(Y)\big) \\
		\end{pmatrix}\Bigg) }
	\end{align*}
	\onslide<4->{
		Sei die \reward{} $S$ auf $M$ definiert als
		\begin{equation*}
		S: Q^2 \to \mathbb{R} : (s,t) \mapsto \big(\mathcal{E}_{t}(X) + X(s,t) - \mathcal{E}_{s}(X)\big)\big(\mathcal{E}_{t}(Y) + Y(s,t) - \mathcal{E}_{s}(Y)\big)\text{.} \label{eq-cov-rew}
		\end{equation*}
	}
	
\end{frame}


\begin{frame}
	Wir erhalten folgendes Gleichungssystem:
	\begin{equation*}
	\begin{aligned}
	c_s & = & 0 && \text{(falls $s \in A$)}\\
	c_s & = & \sum_{t \in Q}P(s,t) \cdot \big(c_t + S(s,t)\big) && \text{(falls $s \notin A$)} 
	\end{aligned} 
	\end{equation*}
	
	\begin{equation*}
	S: Q^2 \to \mathbb{R} : (s,t) \mapsto \big(\mathcal{E}_{t}(X) + X(s,t) - \mathcal{E}_{s}(X)\big)\big(\mathcal{E}_{t}(Y) + Y(s,t) - \mathcal{E}_{s}(Y)\big)
	\end{equation*}
	\pause
	Das Gleichungssystem lässt sich schreiben als:
	\begin{equation*}
	(P_{\rightarrow A} - \mathbb{1}) c = - \left(\sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot S(s,t) }\right)_{s \in Q}
	\end{equation*}
	\pause
	Die Kovarianzen sind die eindeutige Lösung des Gleichungssystems.
\end{frame}

\begin{frame}
	Kovarianzen von $X,Y$ sind Erwartungswerte von $S$:
	\begin{equation*}
	\forall q \in Q : \mcov_q(X,Y) = \mathcal{E}_q(S)
	\end{equation*}
	\pause
	mit
	\begin{equation*}
	S: Q^2 \to \mathbb{R} : (s,t) \mapsto \big(\mathcal{E}_{t}(X) + X(s,t) - \mathcal{E}_{s}(X)\big)\big(\mathcal{E}_{t}(Y) + Y(s,t) - \mathcal{E}_{s}(Y)\big)
	\end{equation*}
	\pause
	weil...
	\begin{equation*}
	(P_{\rightarrow A} - \mathbb{1}) c = - \left(\sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot S(s,t) }\right)_{s \in Q}
	\end{equation*}
\end{frame}


\begin{frame}
	Algorithmus zur Berechnung von \cov{}en $\mcov_q(X,Y)$ :
	\begin{itemize}
		\item Berechne Erwartungswerte $\mexp_{q}(X)$ und $\mexp_{q}(Y)$ \pause
		\item Berechne $S$ als neue Gewichtsfunktion mit
		\begin{align*}
		S:& Q^2 \to \mathbb{R} : \\
		&(s,t) \mapsto \big(\mathcal{E}_{t}(X) + X(s,t) - \mathcal{E}_{s}(X)\big)\big(\mathcal{E}_{t}(Y) + Y(s,t) - \mathcal{E}_{s}(Y)\big)
		\end{align*} \pause
		\item Berechne Erwartungswerte $\mathcal{E}_q(S)$
	\end{itemize}
\end{frame}


\subsection{Berechnung von Varianzen}

\begin{frame}
	\begin{itemize}
	\item Sei $R = X = Y$. Dann ist $\mcov_q(X,Y)	= \mvar_q(X)$. \pause
	\item Der Vektor der Varianzen ist die eindeutige Lösung von
	\begin{equation*}
	(P_{\rightarrow A} - \mathbb{1}) \nu = - \left(\sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot S(s,t) }\right)_{s \in Q}\text{.}
	\end{equation*} \pause
	\item Dabei lässt sich $S$ vereinfachen zu:
	\begin{equation*}
		S: Q^2 \to \mathbb{R}_+ : (s,t) \mapsto \big(\mathcal{E}_{t}(R) + R(s,t) - \mathcal{E}_{s}(R)\big)^2
	\end{equation*}
\end{itemize}
\end{frame}

\begin{frame}
	Algorithmus zur Berechnung von \alt<-1>{\cov{}en}{\textcolor{green}{\var{}en}} \alt<-2>{$\mcov_q(X,Y)$}{{\color{green} $\mvar_q(X)$}}:
	\begin{itemize}
		\item Berechne Erwartungswerte $\mexp_{q}(X)$ \alt<-3>{und $\mexp_{q}(Y)$}{\textcolor{red}{\sout{ und $\mexp_{q}(Y)$}}} 
		\item Berechne $S$ als neue Gewichtsfunktion mit
		\begin{align*}
		S:& Q^2 \to \mathbb{R} : \\
		\only<-4>{&(s,t) \mapsto \big(\mathcal{E}_{t}(X) + X(s,t) - \mathcal{E}_{s}(X)\big)\big(\mathcal{E}_{t}(Y) + Y(s,t) - \mathcal{E}_{s}(Y)\big)} 
		\only<5->{&(s,t) \mapsto \big(\mathcal{E}_{t}(R) + R(s,t) - \mathcal{E}_{s}(R)\big)^2}
		\end{align*}
		\item Berechne Erwartungswerte $\mathcal{E}_q(S)$
	\end{itemize}

\end{frame}

\begin{comment}
	
\begin{frame}
	\only<-2>{{\large \bfseries \centering Beispiel (Fortsetzung)\\}} \pause
	Zunächst berechnen wir die konkrete Gewichtsfunktion $S$:
	\[
	S: Q^2 \to \mathbb{R}_+ : (s,t) \mapsto \big(\mathcal{E}_{t}(R) + R(s,t) - \mathcal{E}_{s}(R)\big)^2
	\]
	\pause
	 als Matrix:
	\only<3>{\begin{equation*}
	S = \begin{pmatrix}
	0 & 16 & 16 & 1 & 100 & 100 \\
	64 & 0 & 49 & 81 & 4 & 0 \\
	1 & 4 & 0 & 16 & 36 & 81 \\
	1 & 81 & 4 & 4 & 64 & 121 \\
	100 & 4 & 81 & 121 & 0 & 9 \\
	100 & 4 & 81 & 121 & 49 & 0 \\
	\end{pmatrix}
	\end{equation*}
	}
	\only<4->{\begin{equation*}
		\tilde{S} = \begin{pmatrix}
		0 & \alt<-4>{16}{\textcolor{red}{16}} & 16 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 & 0 & 0 \\
		0 & 4 & 0 & 16 & 36 & 0 \\
		0 & 0 & 0 & 4 & 64 & 0 \\
		0 & 0 & 0 & 0 & 0 & 0 \\
		0 & 0 & 0 & 0 & 0 & 0 \\
		\end{pmatrix}
		\end{equation*}
	(ohne irrelevante Einträge)\\}
	\onslide<5>{ $S(1,2) = (2 + 4 - 10)^2 = 16$ }
\end{frame}

\begin{frame}
	\mcexgr
\end{frame}

\begin{frame}
	\begin{align*}
	c &\coloneqq - \left(\sum_{t \in Q}{ P_{\rightarrow \{5,6\}}(s,t) \cdot S(s,t) }\right)_{s \in Q} \\
	\onslide<2->{&= - \left(\sum_{t \in Q}{ P_{\rightarrow \{5,6\}}(s,t) \cdot \tilde{S}(s,t) }\right)_{s \in Q} \\}
	\onslide<3->{&= \begin{pmatrix} -16 & 0 & -18 & -16 & 0 & 0 \end{pmatrix}^\intercal}
	\end{align*}
	\onslide<4->{
	\begin{equation*}
	(P_{\rightarrow \{5,6\}} - \mathbb{1}) \nu = c
	\end{equation*}
	}
	\onslide<5->{
	Wir erhalten für $\nu \coloneqq (P_{\rightarrow \{5,6\}} - \mathbb{1})^{-1}c$ den Vektor
	\begin{equation*}
	\nu = \begin{pmatrix} 45 & 0 & 58 & 80 & 0 & 0 \end{pmatrix}^\intercal\text{.}
	\end{equation*}
	}
\end{frame}

\begin{frame}
	\mcexgr
\end{frame}
%\ end{comment}

\subsection{Die initiale Verteilung}

\begin{frame}
	\begin{itemize}
		\item bisher: Start in einem speziellen Zustand \pause
		\item \mc{} \mcex{} $\rightarrow$ Start i.A. nicht eindeutig \pause
		\item $I : Q \to [0,1]$ \hfill $\mu = \sum_{q\in Q}{I(q) \cdot \mu_q}$ \pause
		\item Trick: neuer Startzustand $q_{start} \notin Q$ \pause
		\begin{itemize}
			\item $Q' \coloneqq Q \cup \{q_{start}\}$ \pause
			\item Sei  $I'$ gegeben durch $I'(q) \coloneqq \begin{cases}
			1 & q = q_{start}\\
			0 & q \neq q_{start}
			\end{cases}$
%			\end{equation*}
			\pause
			\vspace{1ex}
			\item Sei $P'$ gegeben durch %\begin{equation*}
			$P'(s, t)  \coloneqq \begin{cases}
			I(t) & s = q_{start} \land t \in Q \\
			0 & t = q_{start}\\
			P(s,t) & s,t \in Q
			\end{cases}$
%			\end{equation*}
			\pause
			\vspace{1ex}
			\item  neue \mc{} $M'=(Q',P',I')$
		\end{itemize}
		
		\begin{align*}
	\mathcal{E}(R) \coloneqq \;& \mathcal{E}_{(\mathrm{Paths}_{q_{start} \rightarrow A}(M'), P')}(R) \\
	\mvar(R) \coloneqq \;& \mvar_{(\mathrm{Paths}_{q_{start} \rightarrow A}(M'), P')}(R) \\
	\mcov(R,S) \coloneqq \;& \mcov_{(\mathrm{Paths}_{q_{start} \rightarrow A}(M'), P')}(R,S) \\
	\end{align*}
		
	\end{itemize}
\end{frame}

\subsection{Komplexität}


\begin{frame}
Auszuführende Schritte:
	\begin{itemize}
		\item Berechne die Matrix $M \coloneqq (P_{\rightarrow A} - \mathbb{1})$! \pause
		\begin{itemize}
			\onslide<5->{\item $\mathcal{O}(|Q^2|)$\onslide<6->{, sogar in $\mathcal{O}(\#edges)$, falls $\#edges \geq |Q|$ }}
		\end{itemize}
		\item Berechne den Vektor $b \coloneqq - \left(\sum_{t \in Q}{ P_{\rightarrow A}(s,t) \cdot R(s,t) }\right)_{s \in Q}$! \pause
		\begin{itemize}
			\onslide<7->{\item $\mathcal{O}(\#edges)$}
		\end{itemize}
		\item Löse das lineare Gleichungssystem $Mx = b$! \pause
		\begin{itemize}
			\onslide<10->{\item Gauß-Jordan-Verfahren: $\mathcal{O}(|Q|^3)$}
			\onslide<11->{\item Explizite Lösung ohne Verlust von Genauigkeit:  $\mathcal{O}(n^3(\log n)^2)$ [Dixon1982]}
			\onslide<12->{\item Untere Schranke (Einlesen der Matrix): $\mathcal{O}(\#edges)$}
		\end{itemize}
		\item Varianzen, \cov{}en: Berechne neuen Reward, wiederhole!
		\begin{itemize}
			\onslide<8->{\item $\mathcal{O}(\#edges)$}
			\onslide<9>{\[
				S: Q^2 \to \mathbb{R}_+ : (s,t) \mapsto \big(\mathcal{E}_{t}(R) + R(s,t) - \mathcal{E}_{s}(R)\big)^2
				\]}
		\end{itemize}
	\end{itemize}
	\onslide<13->{Die Zeit ist im Wesentlichen abhängig vom Algorithmus zum Lösen des Gleichungssystems.}
\end{frame}

\section{Performancemessung am praktischen Beispiel}

\begin{frame}
	Problembeschreibung
	\begin{itemize}
		\item Netzwerk von $n$ identischen Prozessen
		\item Ringtopologie mit unidirektionaler Kommunikation
	\end{itemize} \pause
	Welche Beispiele betrachten wir?
	\begin{itemize}
		\item \textit{Herman's self-stabilising algorithm} \pause
		\item \textit{Synchronous Leader Election Protocol} von Itai und Rodeh \pause
		\item Modelle aus den \textit{PRISM Case Studies}
	\end{itemize} \pause
	Implementation:
	\begin{itemize}
		\item Sprache: C++ \pause
		\item Berechnung von Erwartungswerten, Varianzen und Kovarianzen \pause
		\item header-only C++ library \textit{AMGCL} von Demidov
		\item algebraische Mehrgitterverfahren zum näherungsweisen Lösen großer linearer Gleichungssysteme
	\end{itemize}
\end{frame}


\begin{comment}

\subsection{Implementation}

Zu dieser schriftlichen Abhandlung wurde eine Implementierung der vorgestellten Berechnungsmethoden angefertigt und ist öffentlich auf \textit{github.com} einsehbar \cite{MCA}. Wir wollen diese Implementation nutzen, um die Performance der vorgestellten Verfahren an den eben genannten Beispielen zu testen. Zunächst sollen aber hier der wesentliche Aufbau und die wesentlichen Features der Softwarelösung kurz beschrieben werden und auf die verwendeten Bibliotheken eingegangen werden.


Das Tool \textit{MC Analyzer} \cite{MCA} wurde in der Sprache C++ geschrieben und liefert Algorithmen zur Berechnung von Erwartungswerten, Varianzen und Kovarianzen von akkumulierten Kantengewichten in \mc n.
Dazu muss zunächst eine \mc{} geladen werden. Hierfür ist es möglich Dateien, wie \textit{PRISM} \cite{PRISMCS} sie verwendet, einzulesen oder vom Tool eine \mc{} für den Algorithmus von Herman (\ref{alg-herman}) erzeugen zu lassen. Weiterhin wird ein eigens mitgebrachtes Dateiformat akzeptiert. Beispiele finden sich auf GitHub. Nachdem eine \mc{} und eine Menge an Zielzuständen eingelesen wurden, lassen sich Operationen zur Berechnung von Erwartungswert, Varianz bzw. \cov{} in einzelnen Schritten ausführen. Dabei schreibt das Tool Messwerte in die Standardausgabe, aus denen unter anderem die Dauer einzelner Berechnungsschritte hervorgeht. Details zur Verwendung sind online beschrieben \cite{MCA}.


Zum Lösen linearer Gleichungssysteme wurde die \textit{header-only C++ library AMGCL} von Demidov \cite{Demidov2019} verwendet. Diese verwendet algebraische Mehrgitterverfahren zum näherungsweisen Lösen großer linearer Gleichungssysteme mit dünnbesetzter Koeffizientenmatrix $A_1$. 
%Im Prinzip löst diese Implementation Gleichungssysteme mit vergleichsweise kleinen Matrizen direkt. Sobald die Koeffizientenmatrix eine gewisse Größe überschreitet, so wird eine Matrix von kleinerer Dimension 
Ist eine Koeffizientenmatrix $A_i$ zum direkten Lösen in angemessener Zeit zu groß, wird so lange eine gröbere Matrix $A_{i+1}$ geringerer Dimension gebildet zusammen mit einem sogenannten Prolongationsoperator $P_i$ und einem sogenannten Restriktionsoperator $R_i$ mit $A_{i+1} = R_iA_iP_i$, bis wir eine in vernünftiger Zeit direkt lösbare Matrix $A_n$ erhalten. Nachdem solch eine Hierarchie aufgestellt worden ist, werden zunächst von der feinsten bis zur gröbsten Hierarchieebene jeweils iterativ Näherungslösungen berechnet. Die Fehler werden durch Anwenden der Restriktionsoperation in die jeweils gröbere Hierarchiestufe propagiert. Das lineare Gleichungssystem aus der gröbsten Stufe wird direkt gelöst. Danach werden die Hierarchieebenen in umgekehrter Reihenfolge betrachtet, jeweils die Lösung der gröberen Ebene wird in die feinere propagiert unter Anwendung des Prolongationsoperators. In jeder Ebene werden dabei verbliebene Fehler iterativ minimiert. Nähere Details bietet der Artikel von Demidov \cite{Demidov2019}.

Da in diesem Verfahren einzelne Schritte stets Restfehler verkleinern, tritt im Gegensatz zur klassischen Methode von Gauß-Jordan zum direkten Lösen linearer Gleichungssysteme nicht das typische Problem der numerischen Instabilität in Verbindung mit der floating-point Arithmetik auf. Dieses provozieren wir zum Beispiel, wenn wir zwei positive Zahlen mit sehr geringen Beträgen am Rande des Darstellbaren multiplizieren und in der floating-point Arithmetik als Resultat eine $0$ erhalten, da die Genauigkeit nicht mehr ausreicht.

%\ end{comment}

\subsection{Analyse der Messwerte}

\begin{frame}
	\begin{figure}
		\caption{Kantenzahl in Abhängigkeit der Knotenzahl}
		\label{mc-size}
		\centering
		\begin{tikzpicture}
		\begin{axis}[
		xlabel={Knotenzahl},
		ylabel={Kantenzahl},
		xmin=10,
		xmax=1000000,
		xmode=log,
		ymin= 10,
		ymax=60000000,
		ymode=log,
		legend pos=north west,
		ymajorgrids=true,
		grid style=dashed,
		]
		\path[name path=axis] (axis cs:0,0) -- (axis cs:1,0);
		
		\addplot[only marks,color=blue,mark=square,name path=f]
		coordinates {
			(26,33)(69,95)(147,210)(273,397)(459,674)(1059,1570)(61,76)(274,354)(812,1067)(1933,2557)(3962,5257)(12400,16495)(141,172)(1050,1292)(4244,5267)(12709,15833)(31383,39158)(131521,164288)(335,398)(3759,4487)(20884,24979)(78784,94408)(234210,280865)
		};
		
		\addplot[only marks,color=red!50,mark=triangle,]
		coordinates {
			(8,28)(32,244)(128,2188)(512,19684)(2048,177148)(8192,1594324)(32768,14348908)
		};
		
		\addlegendentry{leader\_sync}
		\addlegendentry{herman}
		
		\end{axis}
		\end{tikzpicture}
	\end{figure}
\end{frame}


\begin{frame}
	\begin{figure}
		\caption{Anteil Lösung des Gleichungssystem an Gesamtzeitaufwand}
		\label{fig-percentage}
		\centering
		\begin{tikzpicture}
		\begin{axis}[
		xlabel={Knotenzahl},
		ylabel={},
		xmin=1,
		xmax=300000,
		xmode=log,
		ymin= 40,
		ymax=119,
		legend pos=north west,
		ymajorgrids=true,
		grid style=dashed,
		]
		\path[name path=axis] (axis cs:0,0) -- (axis cs:1,0);
		
		\addplot[only marks,color=blue,mark=square,name path=f]
		coordinates {
			(26,99.6873)(69,99.884)(147,99.6212)(273,99.5649)(459,99.2172)(1059,99.7976)(61,99.8605)(274,99.5487)(812,99.0917)(1933,99.8696)(3962,99.6054)(12400,88.9896)(141,99.6662)(1050,99.2031)(4244,99.3811)(12709,91.1847)(31383,88.7119)(131521,86.8379)(335,99.3776)(3759,98.8887)(20884,86.9314)(78784,85.1208)(234210,85.8437)
		};
		
		\addplot[only marks,color=red,mark=triangle,name path=f]
		coordinates {
			(8,99.8786)(32,96.3183)(128,96.2728)(512,92.9406)(2048,98.7838)(8192,74.852)(32768,76.5769)
		};
		
		\addlegendentry{leader\_sync (in\%)}
		\addlegendentry{herman (in\%)}
		\end{axis}
		\end{tikzpicture}
	\end{figure}
\end{frame}

\begin{frame}
	\begin{figure}
		\caption{Zeitaufwand in Abhängigkeit der Kantenzahl}
		\label{fig-in-edges1}
		\centering
		\begin{tikzpicture}
		\begin{axis}[
		xlabel={Kantenzahl},
		ylabel={Zeit zum Lösen des Gleichungssystems (ms) },
		xmin=10,
		xmax=100000000,
		xmode=log,
		ymode=log,
		ymin= 0.04,
		ymax=1000000,
		legend pos=north west,
		ymajorgrids=true,
		grid style=dashed,
		]
		\path[name path=axis] (axis cs:0,0) -- (axis cs:1,0);
		
		\addplot[ only marks,color=blue,mark=square,name path=f]
		coordinates {
			(33,9.82)(95,66.3707)(210,44.7318)(397,63.0215)(674,58.1665)(1570,495.6469)(76,49.9831)(354,55.259699999999995)(1067,94.4225)(2557,1343.5230000000001)(5257,975.068)(16495,104.6482)(172,44.3029)(1292,116.6879)(5267,669.7491)(15833,129.73489999999998)(39158,251.1644)(164288,1058.4239)(398,53.6763)(4487,340.5793)(24979,138.3345)(94408,524.8805)(280865,1971.8429999999998)
		};
		
		\addplot[only marks,color=red,mark=triangle,name path=f]
		coordinates {
			(28,12.0933)(244,2.6161000000000003)(2188,12.0549)(19684,77.05510000000001)(177148,4900.8295)(1594324,1465.4203)(14348908,15232.2595)
		};
		
		\addlegendentry{leader\_sync}
		\addlegendentry{herman}
		\end{axis}
		\end{tikzpicture}
	\end{figure}
\end{frame}


\begin{frame}
	\begin{figure}
		\caption{Zeitaufwand in Abhängigkeit der Kantenzahl}
		\label{eigen}
		\centering
		\begin{tikzpicture}
		\begin{axis}[
		xlabel={Kantenzahl},
		ylabel={Gesamtzeit zur Varianzermittlung (ms) },
		xmin=10,
		xmax=100000000,
		xmode=log,
		ymode=log,
		ymin= 0.04,
		ymax=1000000,
		legend pos=north west,
		ymajorgrids=true,
		grid style=dashed,
		]
		\path[name path=axis] (axis cs:0,0) -- (axis cs:1,0);
		
		\addplot[ only marks,color=blue,mark=square,name path=f]
		coordinates {
			(33,0.2169)(95,0.4725)(210,0.9264)(397,1.6495)(674,2.9137)(1570,6.4779)(76,0.4179)(354,1.6347)(1067,5.0114)(2557,11.7838)(5257,27.0573)(16495,86.6749)(172,0.8896)(1292,6.4475)(5267,27.8474)(15833,79.8205)(39158,203.4906)(164288,902.0273)(398,1.9912)(4487,23.3781)(24979,132.2275)(94408,570.7666)(280865,1755.6267)
		};
		
		\addplot[only marks,color=red,mark=triangle,name path=f]
		coordinates {
			(28,0.0226)(244,0.2386)(2188,1.5244)(19684,12.5113)(177148,152.4009)(1594324,1617.6304)(14348908,18259.9604)
		};
		
		\addplot[ only marks,color=green,mark=diamond,name path=f]
		coordinates {
			(33,9.8508)(95,66.4478)(210,44.9019)(397,63.2969)(674,58.6254)(1570,496.6521)(76,50.0529)(354,55.5102)(1067,95.288)(2557,1345.2771)(5257,978.931)(16495,117.596)(172,44.4513)(1292,117.6252)(5267,673.9199)(15833,142.2771)(39158,283.1237)(164288,1218.8505)(398,54.0125)(4487,344.4068)(24979,159.1307)(94408,616.63)(280865,2297.0147)
		};
		
		\addplot[only marks,color=orange,mark=star,name path=f]
		coordinates {
			(28,12.108)(244,2.7161)(2188,12.5216)(19684,82.9079)(177148,4961.1665)(1594324,1957.7559)(14348908,19891.462)
		};
		
		\addlegendentry{leader\_sync (Eigen)}
		\addlegendentry{herman (Eigen)}
		
		\addlegendentry{leader\_sync (AMGCL)}
		\addlegendentry{herman (AMGCL)}
		\end{axis}
		\end{tikzpicture}
	\end{figure}
\end{frame}


\begin{frame}
	Grenzen
	\begin{itemize}
		\item schneller Anstieg des Speicherverbrauchs bei \textit{herman}
		\begin{itemize}
			\item \textit{herman\_17}: ca. 60 GB RAM
			\item  exponentielles Wachstum bezüglich der Anzahl der Prozesse im Netzwerk
		\end{itemize} \pause
		\item Aussagen über Rechenzeiten für größere Modelle an dieser Stelle schwierig \pause
		\item Speicherung der \mc{}n:
		\begin{itemize}
			\item Verwendung von Hashmaps
			\item Datenformat von \textit{eigen}
		\end{itemize}
	\end{itemize}
\end{frame}

\section{Ein Blick auf MDPs}
\newcommand{\mdpex}{$M = (Q,A,P,I)$}
\newcommand{\mdp}{Mar\-kow-Ent\-schei\-dungs\-pro\-zess}
\newcommand{\mact}{\mathrm{Act}}


\begin{frame}
	\begin{definition}\label{def-mdp}
		Ein Tupel \mdpex{} nennen wir \mdp{}, wenn gilt:
		\begin{enumerate}[(a)]
			\item $Q$ ist die Menge der Zustände: $|Q|<\infty$.
			\item $A$ ist die Menge der Aktionen: $|A| < \infty$.
			\item $P$ ist eine Funktion $Q \times A \times Q \to [0,1]$ mit
			\begin{equation*}
			\forall q\in Q, \alpha\in A : \sum_{q' \in Q}{P(q,\alpha,q')} \in \{0,1\}
			\end{equation*}
			(Übergangswahrscheinlichkeiten).
			\item initiale Verteilung: $I : Q \to [0,1]$ mit $\sum_{q \in Q}{I(q)} = 1$
			\item In jedem Zustand ist mindestens eine Aktion verfügbar:
			\begin{equation*}
			\forall q\in Q : 0 < | \mathrm{Act}(q) | < \infty
			\end{equation*}
			$\mathrm{Act}(q) \coloneqq \{\alpha \in A \mid \exists q' \in Q : P(q,\alpha,q') > 0\}$
		\end{enumerate}
	\end{definition}	
\end{frame}

\newcommand{\msch}{\mathrm{Schedulers}}
\begin{frame}
	\begin{definition}
		Sei \mdpex{} ein \mdp{} (MDP). Ein Scheduler für $M$ ist eine Funktion $\mathcal{S} : Q^+ \to A$ mit der Eigenschaft
		\begin{equation*}
		\forall n \in \mathbb{N}_{>0}, \pi \in Q^n\ : \mathcal{S}(\pi) \in \mathrm{Act}(\pi_{n-1})\text{.}
		\end{equation*}
		\begin{itemize}
			\item  $\pi = (\pi_0, \pi_1, \dots , \pi_{n-1})$
			\item $Q^+ \coloneqq \bigcup_{n \in \mathbb{N}_{>0}} Q^n$
			\item  $\mathrm{Schedulers}(M)$: Menge aller Scheduler für $M$
		\end{itemize}
	\end{definition}
	\pause
	\begin{itemize}
		\item MDP $M, \mathcal{S} \in \mathrm{Schedulers}(M) \longrightarrow$ \mc{} $M_{\mathcal{S}}$ \pause
		\item \reward{}en für MDPs, Menge von Zielzuständen \pause
		\item Problem: $\mathcal{S}$ so wählen, dass $\mvar(M_{\mathcal{S}})$ möglichst klein wird
	\end{itemize}
	
\end{frame}

\subsection{Resultierende \mc{}n}
\newcommand{\gmc}{generische \mc{}}

\begin{frame}
	\frametitle{Formalisierung von  $M_{\mathcal{S}}$}
	\begin{definition}
		Seien \mdpex{} ein MDP, $S\in \msch(M)$ ein Scheduler für $M$ und $q\in Q$ ein beliebiger Zustand von $M$. Dann definieren wir:
		\begin{equation*}
		S_{\leftarrow q} : Q^+ \to A : (p_0,\dots,p_{n-1}) \mapsto S(q,p_0,\dots,p_{n-1})
		\end{equation*}
		$S_{\leftarrow q}$ ist offensichtlich wieder ein Scheduler für $M$: $S_{\leftarrow q} \in \msch(M)$
	\end{definition}
	\begin{definition}
		Eine Tupel $G=(Q,P)$ heißt \gmc{}, wenn eine \mc{} $M$ mit \mcex{} existiert.
	\end{definition}
\end{frame}
\newcommand{\mgen}{\mathrm{Gen}}


\begin{frame}
	\begin{definition}
		Sei \mdpex{} ein MDP. Mit
		\begin{equation*}
		\mgen(M):= (\mathrm{Schedulers}(M)\times Q,\tilde{P})
		\end{equation*}
		bezeichnen wir die \gmc{} zu $M$. Dabei sei $\tilde{P}$ definiert als: \pause
		\begin{align*}
		\tilde{P} &: (\mathrm{Schedulers}(M)\times Q) \times (\mathrm{Schedulers}(M)\times Q) \to [0,1]\text{ , mit} \nonumber \\
		&\big((\mathcal{S}_1,q),(\mathcal{S}_2,q')\big) \mapsto \begin{cases}
		P(q,\alpha,q') & \text{falls } \mathcal{S}_2 = (\mathcal{S}_1)_{\leftarrow q}, \alpha = \mathcal{S}_1(q)\\
		0 & \text{sonst}
		\end{cases}
		\end{align*}
	\end{definition}
\end{frame}


\begin{frame}
		\frametitle{resultierende \mc{} $M_{\mathcal{S}}$}
	\begin{itemize}
		\item  MDP \mdpex{}
		\item Scheduler $\mathcal{S}\in \msch(M)$ \pause
		\item resultierende \mc{}: $M_\mathcal{S} := (Q',P',I')$ mit \pause
	\end{itemize}
\begin{align*}
(Q',P') &:= \mgen(M) \\
I'(\mathcal{S}',q) &:= \begin{cases}
I(q) & \text{falls }\mathcal{S}'=\mathcal{S}\\
0 & \text{sonst}
\end{cases}
\end{align*}
\end{frame}

\begin{frame}
	\begin{itemize}
		\item Gewichtsfunktion:
		\begin{equation*}
		R : Q \times A \times Q \to \mathbb{R}_{\geq 0}\text{.}
		\end{equation*} \pause
		\item Gewichtsfunktion $\tilde{R}$ der resultierenden \mc{}:
		\begin{equation*}
		\tilde{R}\big((\mathcal{S},q), (\mathcal{S}_{\leftarrow q},q')\big) = R(q,\mathcal{S}(q),q')
		\end{equation*} \pause
		\item bekannt: Wahrscheinlichkeit zum Erreichen einer Menge an Zuständen im MDP maximieren: Memoryless Scheduler genügt. \pause
		\item Reichen memoryless Scheduler für unser Problem?
	\end{itemize}
	
\end{frame}


\begin{frame}
		Nein!
		\begin{center}
			\begin{tikzpicture}[auto,swap,scale=3]
			
			% First we draw the vertices
			\foreach \pos/\name in {{(0,0)/1}, {(2,0)/2}}
			\node[vertex] (\name) at \pos {$\name$};
			
			% First we draw the vertices
			\foreach \pos/\name in {{(1,1)/3}}
			\node[target] (\name) at \pos {$\name$};
			
			% Connect vertices with edges and draw weights
			\foreach \source/ \dest /\weight in {
				1/3/{\alpha:\frac{1}{2}:5},
				2/3/{\beta:\frac{1}{10}:0}
			}
			\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
			
			% Connect vertices with edges and draw weights
			\foreach \source/ \dest /\weight in {
				2/3/{\alpha:1:2},
				1/2/{\alpha:\frac{1}{2}:1}
			}
			\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
			
			% Connect vertices with edges and draw weights
			%\foreach \source/ \dest /\weight in {
			%}
			%\path[edge] (\source) to node[weight]{$\weight$} (\dest);
			
			\foreach \source/ \dest /\weight in {
				2/2/{\beta:\frac{9}{10}:2}
			}
			\path[edge] (\source) to[loop right] node[weight]{$\weight$} (\dest);
			
			\foreach \source/ \dest /\weight in {
				3/3/{\alpha:1:7}
			}
			\path[edge] (\source) to[loop above] node[weight]{$\weight$} (\dest);
			
			% Draw initial state
			\path[edge] (-0.5,0) to (1);
			
			\end{tikzpicture}
		\end{center}
\end{frame}

\begin{frame}
	Memoryless Scheduler:
	\begin{itemize}	\item Wähle $2 \mapsto \alpha$
	\begin{itemize}
		\item $\mexp(R) = 4$
		\item $\mvar(R) = 1$
	\end{itemize}
	\item Wähle $2 \mapsto \beta$ \pause
	\begin{itemize}
		\item $\mexp_{2}(R) = 18$ sowie $\mexp_{1}(R) = 12$
		\item $\mvar(R) = \frac{1}{2} \cdot (12 - 5)^2 + \dots \geq \frac{49}{2}$
	\end{itemize}
	\end{itemize} \pause
	Aber: Wähle genau einmal $\beta$, falls möglich:
\begin{itemize}
\item $\mexp(R) = 4,8$ 
\item  $\mvar(R) = 0,76$
\end{itemize}	
\end{frame}

\begin{frame}
		Aber: Wähle genau einmal $\beta$, falls möglich:
	\begin{itemize}
		\item $\mexp(R) = 4,8$ 
		\item  $\mvar(R) = 0,76$
	\end{itemize}
	\begin{center}
		\begin{tikzpicture}[auto,swap,scale=3]
		
		% First we draw the vertices
		\foreach \pos/\name in {{(0,0)/1}, {(1,0)/2_1}, {(2,0)/2_2}}
		\node[vertex] (\name) at \pos {$\name$};
		
		% First we draw the vertices
		\foreach \pos/\name in {{(1,1)/3}}
		\node[target] (\name) at \pos {$\name$};
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			1/3/{\frac{1}{2}:5},
			2_1/3/{\frac{1}{10}:0}
		}
		\path[edge] (\source) to[bend left] node[weight]{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		\foreach \source/ \dest /\weight in {
			2_2/3/{1:2},
			1/2_1/{\frac{1}{2}:1},
			2_1/2_2/{\frac{9}{10}:2}
		}
		\path[edge] (\source) to[bend right] node{$\weight$} (\dest);
		
		% Connect vertices with edges and draw weights
		%\foreach \source/ \dest /\weight in {
		%}
		%\path[edge] (\source) to node[weight]{$\weight$} (\dest);
		
		\foreach \source/ \dest /\weight in {
			3/3/{1:7}
		}
		\path[edge] (\source) to[loop above] node[weight]{$\weight$} (\dest);
		
		% Draw initial state
		\path[edge] (-0.5,0) to (1);
		
		\end{tikzpicture}
	\end{center}
\end{frame}

\subsection{Ein Ansatz zum Minimieren von Varianzen}
\newcommand{\vt}{Target-Varianz}
\newcommand{\mvt}{\mathcal{V}\!ar \mathcal{T}\!\!ar}
\newcommand{\vtex}{$\mvt(M_{\mathcal{S}},x)$}

\begin{frame}
	Intuition:
	\begin{itemize}
		\item Angenommen: Erwartungswert $\mu$ zu optimalem Scheduler bekannt
		\item Aktionen so wählen, dass $\mu$ möglichst gut erreicht wird
	\end{itemize} \pause

\[
\mvar^{\mathcal{S}}(R) = \sum_{q \in Q}{I(q)} \cdot \sum_{\pi \in \pfin_{(\mathcal{S},q) \rightarrow (\msch(M)\times T)}(\mgen(M))}{\hspace{-5ex}\tilde{P}(\pi) \cdot (\tilde{R}(\pi) - \mu^{\mathcal{S}})^2}
\]
\end{frame}


\begin{frame}
	\begin{definition}[\vt]\label{def-vt}
		Seien \probspaceex{} ein \probspace{}, $X$ eine \rvar{} auf \probspaceex{} und $t \in \mathbb{R}$. Mit
		\begin{equation*}
		\mvt_{\probspaceexraw{}}(X,t) \coloneqq \mathcal{E}_{\probspaceexraw{}}\left(\left(X - t\right)^{2}\right)
		\end{equation*}
		bezeichnen wir die \vt{} von $X$ zum Ziel $t$ auf  \probspaceex{}. Sollte der Kontext \probspaceex{} klar sein, schreiben wir kurz $\mvt(X,t)$.
	\end{definition} \pause

	$\mvt_{\probspaceexraw{}}(X,\mu) = \mvar_{\probspaceexraw{}}(X)$, wenn $\mu = \mathcal{E}_{\probspaceexraw{}}(X)$
\end{frame}


\begin{frame}
	\begin{lemma}\label{lem-vtqf}
		Sei \probspaceex{} ein \probspace{}, $X$ eine \rvar{} auf \probspaceex{} und $t \in \mathbb{R}$. Dann gilt:
		\begin{equation*}
		\mvt(X,t) = \left(t - \mathcal{E}(X)\right)^2 + \mvar(X)
		\end{equation*}
	\end{lemma}
\vspace{-2ex}
	\begin{align*}
	& \mvt(X,t) \\
	& =  \sum_{\omega \in \Omega}{P(\omega) \cdot \left((X(\omega)-t)^2\right)} \\
	%\implies & & f(t) & = \sum_{\omega \in \Omega}{P(\omega) \cdot \left(t^2 -2tX(\omega) + \left(X(\omega)\right)^2\right)} \\
	& = \sum_{\omega \in \Omega}{P(\omega) \cdot \left(t^2 -2tX(\omega) + \left(\mathcal{E}(X)\right)^2 - \left(\mathcal{E}(X)\right)^2 + \left(X(\omega)\right)^2\right)} \\
	& = \left(t - \mathcal{E}(X)\right)^2 - \left(\mathcal{E}(X)\right)^2 + \mathcal{E}(X^2) \\
	& = \left(t - \mathcal{E}(X)\right)^2 + \mvar(X)
	\end{align*}
\end{frame}

\begin{frame}
	\begin{korollar}\label{kor-vtt-rel}
		Sei \probspaceex{} ein \probspace{}, $X$ eine \rvar{} auf \probspaceex{} und $t \in \mathbb{R}$. Dann gilt:
		\begin{equation*}
		\mvt(X,t) \geq \mvar(X)
		\end{equation*}
	\end{korollar}

\begin{lemma} Sei $M$ ein MDP und $R$ eine Gewichtsfunktion auf $M$. Dann gilt:
	\begin{equation*}
	\inf_{\mathcal{S} \in \mathrm{Schedulers}(M)}{\mvar^{\mathcal{S}}(R)}
	=
	\inf_{t \in \mathbb{R}_{\geq 0}}{
		\:\inf_{\mathcal{S} \in \mathrm{Schedulers}(M)}{
			\mvt^{\mathcal{S}}(R,t)
		}
	}
	\end{equation*}
\end{lemma}
\end{frame}

\begin{frame}
	\begin{center}
		\begin{tikzpicture}
		\begin{axis}[
		xlabel={$t$},
		ylabel={$\mvt(M_\mathcal{S},t)$},
		xlabel style={below right},
		ylabel style={above left},
		axis x line=center,
		axis y line=center,
		xmin=0,
		xmax=16,
		ymin= 0.1,
		ymax=99.9,
		%xmode=log,
		%ymode=log,
		%legend pos=north west,
		%ymajorgrids=false,
		%grid style=dashed,
		]
		%\draw[very thin,color=gray] (-0.1,-0.1) grid (9.9,299.9);
		%\draw[->] (-0.2,0) -- (10.2,0) node[right] {$t$};
		%\draw[->] (0,-0.2) -- (0,300.2) node[above] {$\mvt(M_\mathcal{S},t)$};
		\addplot[domain=0:11] function{(x-4)*(x-4)+1} 
		node[above] {$\mathcal{S}_0$};
		\addplot[domain=0:12] function{(x-4.8)*(x-4.8)+0.76} 
		node[above] {$\mathcal{S}_1$};
		\addplot[domain=0:13] function{(x-5.52)*(x-5.52)+2.32} 
		node[above] {$\mathcal{S}_2$};
		\addplot[domain=0:14] function{(x-6.17)*(x-6.17)+5.45} 
		node[above] {$\mathcal{S}_3$};
		\addplot[domain=0:15] function{(x-6.75)*(x-6.75)+9.87} 
		node[right] {$\mathcal{S}_4$};
		\addplot[domain=0:14] function{(x-7.28)*(x-7.28)+15.37} 
		node[right] {$\mathcal{S}_5$};
		%\addplot[domain=0:15] function{(x-12)*(x-12)+229} 
		%node[right] {$\mathcal{S}_\infty$};
		\end{axis}
		\end{tikzpicture}
	\end{center}
$S_n$: $n$-mal $\beta$ wählen, dann $\alpha$
\end{frame}

\subsection{Minimieren von \vt{}en}

\begin{frame}
	\begin{itemize}
		\item gegebene Stelle $t$ (Target)
		\item Finde den Scheduler $\mathcal{S}$,
		\item sodass $\mvt^{\mathcal{S}}(R,t)$ minimal wird.
	\end{itemize}
\vspace{4ex}
 \pause
 \begin{itemize}
 	\item MDP \mdpex{}
 	\item konkrete Zielmenge $T\subseteq Q$
 	\item Reward $R$
 	\item $(\tilde{Q},\tilde{P}) = \mgen(M)$
 	\item  \vt{} von $\tilde{R}$ zum Ziel $t$ für den Start in $(\mathcal{S},q) \in \tilde{Q}$:
 \end{itemize}
\vspace{2ex}
\[
\mvt_{(\mathcal{S},q)}(\tilde{R},t) = \sum_{\pi \in \pfin_{(\mathcal{S},q) \rightarrow (\msch(M)\times T)}(\mgen(M))}{	\tilde{P}(\pi) \cdot (\tilde{R}(\pi) - t)^2}
\]

\end{frame}

\begin{frame}
	\begin{equation*}
	\mvt^{\mathcal{S}}(R,t) = \sum_{q \in Q}{I(q)} \cdot \mvt_{(\mathcal{S},q)}(\tilde{R},t)
	\end{equation*}
\pause
Für Zielzustände $\tilde{q} \in  (\msch(M) \times T)$ gilt per Definition: \[\mvt_{\tilde{q}}(\tilde{R},t) = t^2\]
\pause
\begin{lemma}
	Sei $\tilde{q} \in \tilde{Q} \setminus (\msch(M)\times T)$ kein Zielzustand. Dann gilt:
	\begin{equation*}
	\mvt_{\tilde{q}}(\tilde{R},t) = \sum_{\tilde{q}' \in \tilde{Q}} P(\tilde{q},\tilde{q}') \cdot \mvt_{\tilde{q}'}\big(\tilde{R},t -\tilde{R}(\tilde{q},\tilde{q}')\big)
	\end{equation*}
\end{lemma}

\end{frame}

\begin{frame}
	\begin{proof}
		Sei $\tilde{T} := \msch(M)\times T$. Wir können den ersten Zustandsübergang des Pfades gesondert betrachten und erhalten:
		\begin{align*}
		&\mvt_{\tilde{q}}(\tilde{R},t)\\
		=& \sum_{\tilde{q}' \in \tilde{Q}} \cdot \sum_{\pi' \in \pfin_{\tilde{q}' \rightarrow \tilde{T}}(\mgen(M))}{\hspace{-3ex}\tilde{P}(\tilde{q},\tilde{q}') \cdot \tilde{P}(\pi') \cdot (\tilde{R}(\tilde{q},\tilde{q}') + \tilde{R}(\pi') - t)^2}\\
		=& \sum_{\tilde{q}' \in Q} \tilde{P}(\tilde{q},\tilde{q}') \cdot \sum_{\pi' \in \pfin_{\tilde{q}' \rightarrow \tilde{T}}(\mgen(M))}{\hspace{-3ex}\tilde{P}(\pi') \cdot \big(\tilde{R}(\pi') - (t- \tilde{R}(\tilde{q},\tilde{q}'))\big)^2}\\
		=& \sum_{\tilde{q}' \in Q} \tilde{P}(\tilde{q},\tilde{q}') \cdot \mvt_{\tilde{q}'}\big(\tilde{R},t -\tilde{R}(\tilde{q},\tilde{q}')\big)
		\end{align*}
	\end{proof}
\end{frame}

\begin{frame}
	Definieren wir uns eine Funktion
	\begin{equation*}
	g : Q \times \mathbb{R} \to \mathbb{R} : (q,t) \mapsto \inf_{\mathcal{S} \in \mathrm{Schedulers}(M)}(\mvt_{(\mathcal{S},q)}(\tilde{R},t))\text{,}
	\end{equation*}
	
	
	dann gilt für $q\notin T$: \pause
 \begin{align*}
	 &g(q,t)\\
		\hspace{-5ex}=& \inf_{\mathcal{S} \in \mathrm{Schedulers}(M)}\mvt_{(\mathcal{S},q)}(\tilde{R},t) \\
		\hspace{-5ex}=& \inf_{\mathcal{S} \in \mathrm{Schedulers}(M)}\sum_{\tilde{q}' \in Q} \tilde{P}\big((\mathcal{S},q),\tilde{q}'\big) \cdot \mvt_{\tilde{q}'}\Big(\tilde{R},t -\tilde{R}\big((\mathcal{S},q),\tilde{q}'\big)\Big) \\
		\hspace{-5ex}=& \inf_{\mathcal{S} \in \mathrm{Schedulers}(M)}\sum_{q' \in Q} P(q,\mathcal{S}(q),q') \cdot \mvt_{(\mathcal{S}_{\leftarrow q},q')}\big(\tilde{R},t -R(q,\mathcal{S}(q),q')\big)\\
		\hspace{-5ex}=& \inf_{\alpha \in \mathrm{Act}(q)}\sum_{q' \in Q} P(q,\alpha,q') \cdot \inf_{\mathcal{S'} \in \mathrm{Schedulers}(M)} \mvt_{(\mathcal{S'},q')}\big(\tilde{R},t -R(q,\alpha,q')\big)\\
		\hspace{-5ex}=& \min_{\alpha \in \mathrm{Act}(q)}\sum_{q' \in Q} P(q,\alpha,q') \cdot g\big(q',t -R(q,\alpha,q')\big)
	\end{align*}
\end{frame}
\newcommand{\msel}{\mathrm{sel}}

\begin{frame}
	Es  gilt für $q\in T$:
	\begin{equation*}\label{eq-gt2}
	g(q,t) = t^2\text{.}
	\end{equation*} \pause
	\begin{equation*}
	\inf_{\mathcal{S} \in \mathrm{Schedulers}(M)}\mvt_{(\mathcal{S},q)}(\tilde{R},t) = \min_{\mathcal{S} \in \mathrm{Schedulers}(M)}\mvt_{(\mathcal{S},q)}(\tilde{R},t)
	\end{equation*}

\end{frame}


\begin{frame}
	Begründung:
	\begin{equation*}
	\msel : Q \times \mathbb{R} \to A : (q,t) \mapsto \argmin_{\alpha \in A}{\sum_{q' \in Q} P(q,\alpha,q') \cdot g\big(q',t -R(q,\alpha,q')\big)}
	\end{equation*}
	\pause
	Wir können den Scheduler formal definieren durch:
	\begin{align*}
	S_t(q) &= \msel(q,t)\\
	S_t(q_0, q_1,\dots,q_n) &= S_{t-R(q,S(q),q_1)}(q_1,\dots,q_n)
	\end{align*}
\pause
Warum ist dieser optimal?
\end{frame}

\begin{frame}
	\only<-3>{
	\begin{lemma}
		\begin{equation*}
		\mvt_{(\mathcal{S}_t,q)}(\tilde{R},t) = g(q,t)
		\end{equation*}
	\end{lemma}
}
\begin{proof}
	\only<2-4>{Offensichtlich gilt $\mvt_{(\mathcal{S}_t,q)}(\tilde{R},t) \geq g(q,t)$.}
	\only<3-4>{Wir zeigen nun noch
	\begin{equation*}\label{eq-goal2577}
	\mvt_{(\mathcal{S}_t,q)}(\tilde{R},t) \leq g(q,t)\text{:}
	\end{equation*}}
	\only<4>{Die \vt{}en von $M_{S_t}$ berechnen sich per Definition durch die folgenden Gleichungen:}
	\only<4>{\begin{align*}
	\forall & t \in \mathbb{R}, q \notin T : \\
	& \mvt_{(\mathcal{S}_t,q)}(\tilde{R},t) = \!\! \sum_{q' \in Q} P(q,S_t(q),q') \cdot \\
	& \hspace{22ex}\cdot \mvt_{((\mathcal{S}_t)_{\leftarrow q},q')}\big(\tilde{R},t - R(q,S_t(q),q')\big) \\
	\forall & t \in \mathbb{R}, q \in T : \\
	& \mvt_{(\mathcal{S}_t,q)}(\tilde{R},t) = t^2
	\end{align*}
}
	\only<5>{
	Dabei können wir die Folge $\big(\lambda_{(\mathcal{S}_t,q)}(\tilde{R},t)_n\mid n \in \mathbb{N}\big)$ betrachten, die gegen $\mvt_{(\mathcal{S}_t,q)}(\tilde{R},t)$ konvergiert, gegeben durch:
	\begin{align*}
	\forall & t \in \mathbb{R}, q \in Q: \\
	& \lambda_{(\mathcal{S},q)}(\tilde{R},t)_0 := 0 \\
	\forall & t \in \mathbb{R}, q \notin T, i \in \mathbb{N}_{>0}: \\
	& \lambda_{(\mathcal{S},q)}(\tilde{R},t)_i := \sum_{q' \in Q} P(q,S(q),q') \cdot \lambda_{(\mathcal{S}_{\leftarrow q},q)}\big(\tilde{R},t - R(q,S(q),q')\big)_{i-1} \\
	\forall & t \in \mathbb{R}, q \in T, i \in \mathbb{N}_{>0} : \\
	& \lambda_{(\mathcal{S},q)}(\tilde{R},t)_i := t^2
	\end{align*}
}
	\only<6>{
	Wir erhalten Gleichung die gewünschte Ungleichung, weil $\lim_{n \to \infty}{\lambda_{(\mathcal{S}_t,q)}(\tilde{R},t)_n} = \mvt_{(\mathcal{S}_t,q)}(\tilde{R},t)$ und da für alle $n\in \mathbb{N}, q\in Q, t \in \mathbb{R}$ gilt:
	\[
	\lambda_{(\mathcal{S}_t,q)}(\tilde{R},t)_n \leq g(q,t)
	\]
	
	Dies zeigen wir per Induktion.} \only<7>{Sei dazu $n_0 \in \mathbb{N}$. Wir nehmen an, die Ungleichung gilt für alle $n<n_0$.
	Falls $n_0 = 0$, so gilt, da \vt{}en immer nichtnegativ sind:
	\[
	\lambda_{(\mathcal{S}_t,q)}(\tilde{R},t)_{n_0} = 0 \leq g(q,t)
	\]}\only<8>{
	Falls $n_0 > 0$, $q\in T$ gilt, so erhalten wir
	\[
	\lambda_{(\mathcal{S}_t,q)}(\tilde{R},t)_{n_0} = t^2 = g(q,t)\text{.}
	\]
	Sei nun $n_0 > 0$, $q\notin T$. Sei weiterhin $t' \coloneqq t - R(q,S_t(q),q')$. Dann erhalten wir
	\vspace{-2ex}
	\begin{align*}
	&\lambda_{(\mathcal{S}_t,q)}(\tilde{R},t)_{n_0} \\
	&= \sum_{q' \in Q} P(q,S_t(q),q') \cdot \lambda_{((\mathcal{S}_t)_{\leftarrow q},q')}\big(\tilde{R},t - R(q,S_t(q),q')\big)_{n_0-1} \\
	&= \sum_{q' \in Q} P(q,S_t(q),q') \cdot \lambda_{(\mathcal{S}_{t'},q')}(\tilde{R},t')_{n_0-1}\\
	&\leq \sum_{q' \in Q} P(q,S_t(q),q') \cdot g\big(q',t -R(q,S_t(q),q')\big) \label{eq-558801}\\
	&= g(q,t) \label{eq-558802}
	\end{align*}
}
	\only<9>{Offensichtlich gilt $\mvt_{(\mathcal{S}_t,q)}(\tilde{R},t) \geq g(q,t)$.}
\only<9>{Wir haben auch gezeigt:
	\begin{equation*}\label{eq-goal2577}
	\mvt_{(\mathcal{S}_t,q)}(\tilde{R},t) \leq g(q,t)\text{:}
	\end{equation*}}
	\end{proof}

\end{frame}






\end{comment}
\begin{comment}



Wir zeigen kurz, dass dieser Scheduler tatsächlich optimal ist:


\begin{comment}
Wir haben also das Problem, für einen gegebenen Zustand $q$ und ein gegebenes Ziel $t$ den Scheduler $\mathcal{S}$ zu finden, der $\mvt_{\mathcal{S},q}(\tilde{R},t)$ minimiert, auf das Bestimmen von $g(q,x)$ für Zustände $q$ und diskrete Stellen $x \in \mathbb{R}$ zurückgeführt. Dieses lässt sich auch als Optimierungsproblem auffassen: Wähle die Funktion $g$ so, dass $g(q,t)$ maximal wird und dabei für alle $x\in \mathbb{R}$ gilt:
\begin{align}
	g(q,x) &= x^2 && \text{falls } q\in T\\
	g(q,x) &\leq \sum_{q' \in Q} P(q,\alpha,q') \cdot g\big(q',x -R(q,\alpha,q')\big) && \text{falls }q \notin T, \alpha \in A
\end{align}

Wie dieses Problem gelöst bzw. effizient gelöst werden kann, lassen wir an dieser Stelle offen.
\end{%comment}

Wie genau der optimale Scheduler bezüglich minimaler \vt{} berechnet werden kann, lassen wir hier offen.
Jedoch könnte man für einen heuristischen Ansatz mit memoryless Schedulern beginnen und diese iterativ verbessern, indem man für bestimmte Stellen $t\in \mathbb{R}$ die zu wählende Aktion ändert, um einen besseren Scheduler zu erhalten. Wir haben bereits gesehen, dass der optimale Scheduler sich als Funktion $S : Q \times \mathbb{R} \to A : (q,t) \mapsto \alpha$ auffassen lässt.
Abschließend möchten wir noch eine Vermutung darlegen:

\begin{vermutung}
	Für jeden MDP \mdpex{} gibt es eine Zahl $t_0\in \mathbb{R}$ sodass für alle $t_1,t_2 < t_0$ und alle Zustände $q\in Q$ gilt:
	\begin{equation}
		\msel(q,t_1) = \msel(q,t_2)
	\end{equation}
	Anders ausgedrückt wird vermutet, dass es genügt, wenn sich $t$ unter einem MDP-spezifischen Schwellwert befindet, ein memoryless Scheduler hinreichend ist, um die optimale Aktion in jedem Zustand zu wählen. 
\end{vermutung}

\section{Zusammenfassung}

Wir haben in dieser Arbeit zuerst einige Grundlagen der Wahrscheinlichkeitstheorie zusammengefasst. Im Anschluss beschrieben wir \mc{}n und endliche Pfade in diesen, welche in einem bestimmten Knoten starten und in einem Knoten einer Zielzustandsmenge enden. Danach haben wir lineare Gleichungssysteme ermittelt, die eindeutig lösbar sind und deren Lösungen die \expect{}e, \var{}en bzw. \cov{}en aufsummierter Kantengewichte auf den eben beschriebenen Pfaden sind.
Wir haben die Methode der Nutzung linearer Gleichungssysteme zur Berechnung probabilistischer Kenngrößen implementiert und benötigte Rechenzeiten für die Ermittlung von Varianzen gemessen, mit dem Ergebnis, dass linear in der Kantenzahl der \mc{} die Zeit zur Berechnung der Varianzen wächst. Zum Schluss haben wir den Blick kurz auf \mdp{}e gelenkt und einen Ansatz betrachtet, wie man den Scheduler für einen MDP finden kann, dessen resultierende \mc{} eine möglichst kleine Varianz aufweist.



\section{Appendix}

Wir wollen nachfolgend solche mathematische Aussagen kurz darlegen und begründen, die nicht zentrales Thema dieser Arbeit sind, jedoch an bestimmten Stellen zur Argumentation herangezogen werden.

\begin{lemma} \label{lem-geosum}
	Seien $n \in \mathbb{N}$ eine natürliche Zahl und $a \in \mathbb{R}_{>0}\setminus\{1\}$. Dann gilt
\begin{equation}
\sum_{i=0}^{n}{a^i} = \frac{a^{n+1}-1}{a-1}
\end{equation}
\end{lemma}
\begin{beweis}
\begin{align*}
	(a-1) \cdot \sum_{i=0}^{n}{a^i} = \sum_{i=0}^{n}{a^{i+1}} - \sum_{i=0}^{n}{a^i} = a^{n+1} - 1
\end{align*}
\end{beweis}

\begin{korollar} \label{kor-geosum}
Betrachten wir den Grenzwert der Summe aus Lemma \ref{lem-geosum} für $n \to \infty$, so ergibt sich für $0<a<1$:
\begin{equation}
\sum_{i=0}^{\infty}{a^i}
= \lim\limits_{n \to \infty} \sum_{i=0}^{n}{a^i}
= \frac{1}{1-a}
\end{equation}
\end{korollar}

\begin{lemma} \label{lem-infsum}
	Seien $n \in \mathbb{N}$ eine natürliche Zahl und $a \in \mathbb{R}_{>0}\setminus\{1\}$. Dann gilt
	\begin{equation}
		\sum_{i=0}^{n}{i\cdot a^i} = \frac{(an-n-1)a^{n+1}+a}{(a-1)^2}
	\end{equation}
\end{lemma}
\begin{beweis}
	\begin{align*}
		&(n+1) a^{n+1} + \sum_{i=0}^{n}{i\cdot a^i} = \sum_{i=0}^{n+1}{i\cdot a^i} = \sum_{i=0}^{n}{(i+1)\cdot a^{i+1}} \\
		=& a \sum_{i=0}^{n}{i\cdot a^{i}} + a \sum_{i=0}^{n}{a^{i}} = a \sum_{i=0}^{n}{i\cdot a^{i}} + a \cdot \frac{a^{n+1}-1}{a-1}\\
		\Rightarrow \quad & (a-1) \sum_{i=0}^{n}{i\cdot a^i} = (n+1) a^{n+1} - a \cdot \frac{a^{n+1}-1}{a-1} 
	\end{align*}
\end{beweis}
\begin{korollar} \label{kor-infsum}
Betrachten wir den Grenzwert der Summe aus Lemma \ref{lem-infsum} für $n \to \infty$, so ergibt sich für $0<a<1$:
\begin{equation}
\sum_{i=0}^{\infty}{i\cdot a^i}
= \lim\limits_{n \to \infty} \sum_{i=0}^{n}{i\cdot a^i}
= \frac{a}{(a-1)^2}
\end{equation}
\end{korollar}

\begin{lemma} \label{lem-infqsum}
	Seien $n \in \mathbb{N}$ eine natürliche Zahl und $a \in \mathbb{R}_{>0}\setminus\{1\}$. Dann gilt
	\begin{equation}
	\sum_{i=0}^{n}{i^2\cdot a^i} = \frac{\big(-a^2n^2 + a(2n^2 + 2n + 1) - (n+1)^2\big)a^{n+1}+a(a+1)}{(a-1)^3}
	\end{equation}
\end{lemma}
\begin{beweis}
	\begin{align*}
		 & n^2a^n + \sum_{i=0}^{n-1}{i^2\cdot a^i} = \sum_{i=0}^{n}{i^2\cdot a^i} = \sum_{i=0}^{n-1}{(i+1)^2\cdot a^{i+1}} \\
		=& a \sum_{i=0}^{n-1}{i^2\cdot a^{i}} + 2a \sum_{i=0}^{n-1}{i\cdot a^{i}} + a \sum_{i=0}^{n-1}{ a^{i}} \\
		=& a \left(\sum_{i=0}^{n}{i^2\cdot a^i} - n^2a^n \right) + 2a \left(\frac{(an-a-n)a^{n}+a}{(a-1)^2} \right) + a \left( \frac{a^{n}-1}{a-1} \right) \\
		\Rightarrow \quad & (1-a) \sum_{i=0}^{n}{i^2\cdot a^i} = -n^2a^{n+1} + 2a \left(\frac{(an-a-n)a^{n}+a}{(a-1)^2} \right) + a \left( \frac{a^{n}-1}{a-1} \right)
	\end{align*}
\end{beweis}
\begin{korollar} \label{kor-infqsum}
Betrachten wir den Grenzwert der Summe aus Lemma \ref{lem-infqsum} für $n \to \infty$, so ergibt sich für $0<a<1$:
\begin{equation}
\sum_{i=0}^{\infty}{i^2\cdot a^i}
= \lim\limits_{n \to \infty} \sum_{i=0}^{n}{i^2\cdot a^i}
= \frac{a\;(a+1)}{(1-a)^3}
\end{equation}	
\end{korollar}

\printbibliography




\end{comment}

\end{document}